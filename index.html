<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Cyberculture and Social Justice Directory</title>
  <meta name="description" content="This is a directory of cyberculture and social justice">
  <meta name="author" content="Alex Ketchum, PhD.">

  <meta property="og:title" content="Cyberculture and Social Justice Directory">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://www.cybercultureandsocialjustice.com/">
  <meta property="og:description" content="This is a directory of cyberculture and social justice">
  <!--<meta property="og:image" content="image.png">-->

  <!--<link rel="icon" href="/favicon.ico">-->
  <!--<link rel="icon" href="/favicon.svg" type="image/svg+xml">-->
  <!--<link rel="apple-touch-icon" href="/apple-touch-icon.png">-->

  <link rel="stylesheet" href="css/styles.css?v=1.0">

</head>

<body class="index">
    <header class="main">
        <h1>Cyberculture and Social Justice Directory</h1>
        <a class="page-link" href="about.html">About</a>
        <input class="searchbar" id="searchbar" onkeyup="searchTags()"
               type="text" placeholder="Search tags...">
    </header><article>
<header class="heading">
<h1>More Work for Mother: the Ironies of Household Technology from the Open Hearth to the Microwave</h1>
<h2>Ruth Schwartz Cowan</h2>
<h3>1985</h3>
</header>
<div class="content">
<p>"In this classic work of women's history (winner of the 1984 Dexter Prize from the Society for the History of Technology), Ruth Schwartz Cowan shows how and why modern women devote as much time to housework as did their colonial sisters. In lively and provocative prose, Cowan explains how the modern conveniences—washing machines, white flour, vacuums, commercial cotton—seemed at first to offer working-class women middle-class standards of comfort. Over time, however, it became clear that these gadgets and gizmos mainly replaced work previously conducted by men, children, and servants. Instead of living lives of leisure, middle-class women found themselves struggling to keep up with ever higher standards of cleanliness." <em>Quoted from summary</em></p>
<p><a target="_blank" href="https://www.basicbooks.com/titles/ruth-schwartz-cowan/more-work-for-mother/9780465047321/">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Technology Studies</label><label>Feminism</label><label>Labour</label><label>History</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Expert systems and women's lives: A technology assessment</h1>
<h2>Margret Bruce and Alison Adam</h2>
<h3>1989</h3>
</header>
<div class="content">
<p>A feminist analysis of "expert systems," which are developped from AI.  Looks into how expert systems recreate gender divisions and how women can influence the design of said technology.</p>
<p><a target="_blank" href="https://www.sciencedirect.com/science/article/abs/pii/0016328789900876">Link to journal with institutional access</a></p>
<p class="tags"><label>Article</label><label>Expert Systems</label><label>Computing</label><label>Gender</label><label>Technology</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Army and the Microworld: Computers and the Politics of Gender Identity</h1>
<h2>Paul N. Edwards</h2>
<h3>1990</h3>
</header>
<div class="content">
<p>This article comments on how despite females rising in their participation in the computer-driven workforce (in the early 90's,) computers and computer related jobs are still seen as a masculine and male-dominated field. These perceptions are accredited to "the modes of thought involved in computer science research, the culture of engineering, and the deeply entangled institutions of military service and of masculinity as a political identity in an age of high technology." <em>Quoted from article</em></p>
<p><a target="_blank" href="https://www-jstor-org.proxy3.library.mcgill.ca/stable/3174609?seq=2#metadata_info_tab_contents">Link to full article</a></p>
<p class="tags"><label>Article</label><label>Gender</label><label>Computing</label><label>Gender disparity</label><label>Industry</label><label>Engineering</label><label>Masculine culture</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Automating Gender: Postmodern Feminism in the Age of the Intelligent Machine</h1>
<h2>Judith/ Jack Halberstam</h2>
<h3>1991</h3>
</header>
<div class="content">
<p>Halberstam evaluates how "the intelligent machines" alter our relationship to gender (Postmodernist Feminism) through the lens of Donna Haraway's Cyborg Manifesto and the Apple logo. "Postmodern feminism ... may benefit from the theory of artificiality.... Such a theory shows that we are already as embedded within the new technologies as they are embodied within us. Both Turing's apple and the female cyborg threaten our ability to differentiate between our natural selves and our machine selves; these images suggest that perhaps already cyborgs are us.</p>
<p><a target="_blank" href="https://www.jstor.org/stable/3178281">Link to article on JSTOR</a></p>
<p class="tags"><label>Article</label><label>Artificial Intelligence</label><label>Postmodern feminism</label><label>Gender</label><label>Cyborg</label><label>Technology</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Women into Computing: Selected Papers 1988-1990</h1>
<h2>Edited by Gillian Lovegrove and Barbara Segal</h2>
<h3>1991</h3>
</header>
<div class="content">
<p>Collection of papers from the Women in Computing Conference, 1988-1990, and deals with the problem generally of less women in computer science majors, and thus computing and technology industries at large.  Interested particularly in schooling, higher education as places to encourage girls and women to go into computing.</p>
<p><a target="_blank" href="https://link.springer.com/content/pdf/10.1007%2F978-1-4471-3875-4.pdf">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Anthology</label><label>Computing</label><label>Gender</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Feminism Confronts Technology</h1>
<h2>Judy Wajcman</h2>
<h3>1991</h3>
</header>
<div class="content">
<p>Feminism Confronts Technology provides a lively and engaging exploration of the impact of technology on women's lives from word processors to food processors, and genetic engineering to the design of cities. Comprehensive and critical, this book surveys the sociological and feminist literature on technology, highlighting the male bias in the way technology is defined as well as developed. Wajcman sets the scene with an overview of feminist theories of science and technology: encompassing the technologies of production and reproduction as well as domestic technology. </p>
<p><a target="_blank" href="https://monoskop.org/images/a/ab/Wajcman_Judy_Feminism_Confronts_Technology_1991.pdf">Link to Free Text</a></p>
<p class="tags"><label>book</label><label>design</label><label>science</label><label>technology</label><label>feminism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Women in AI</h1>
<h2>D Strok</h2>
<h3>1992</h3>
</header>
<div class="content">
<p>A magazine segment about women in AI and computer sciences, obstacles and reccomendations to try and overcome this problem.  Includes first-hand accounts of women in tech and their experiences in the industry.</p>
<p><a target="_blank" href="https://ieeexplore.ieee.org/document/153460">Link to full article</a></p>
<p class="tags"><label>Article</label><label>Artificial Intelligence</label><label>Gender</label><label>AI</label><label>Industry</label><label>Computer Science</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>A Feminist Critique of Artificial Intelligence</h1>
<h2>Alison Adam</h2>
<h3>1995</h3>
</header>
<div class="content">
<p>In this article, Adams critiques AI and expert systems using feminist epistemology, specifically subjectivity (that the epistemology of AI stems from rational objectivity and feminism critiques that stance), the distinction between propositional and skills knowledge (knowledge that people wrote down and deemed true vs. the knowledge women learn through doing things that aren't necessarily recorded that AI can't learn) and the role of the body in the making of knowledge (disembodied knowledge/embodied knowledge).  Concludes that AI systems which employ feminist epistemology are few and far between at the present (1995) but have the potential to map out new areas of AI. </p>
<p><a target="_blank" href="https://doi.org/10.1177/135050689500200305">Link to full article</a></p>
<p class="tags"><label>Article</label><label>AI</label><label>Artificial Intelligence</label><label>Feminist Epistemology</label><label>Subjectivity</label><label>Objectivity</label><label>Gender</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Designing Intersections—Designing Subjectivity: Feminist Theory and Praxis in a Sex Discrimination Legislation System</h1>
<h2>Alison Adam and Chlor Furnival</h2>
<h3>1995</h3>
</header>
<div class="content">
<p>"This paper looks at the intersections between feminist epistemology, feminist jurisprudence and research on artificial intelligence and the law. It is suggested that feminist theory highlights the role of subjectivity which is ignored in the traditional epistemology of AI systems. This allows AI systems to appear to be "perspectiveless" when they may be tacitly used in a normative role which ignores alternative knowledges." Focuses specifically on a case of AI systems trying to provide legal advice for sex discrimination. <em>Quoted from abstract</em></p>
<p><a target="_blank" href="https://doi.org/10.1080/13600834.1995.9965716">Link to full article</a></p>
<p class="tags"><label>Article</label><label>AI</label><label>Artifiical Intelligence</label><label>Law</label><label>Gender</label><label>Subjectivty</label><label>Feminist epistemology</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Modelling Law Using a Feminist Theoretical Perspective</h1>
<h2>Lilian Edwards</h2>
<h3>1995</h3>
</header>
<div class="content">
<p>Edwards discusses artifically intellifent "legal expert systems" that ideally are meant to replace lawyers deductive reasoning and replace a human aspect of the field of law.  She explains how a feminist methodology/epistemology can potentially help curb the inherently white, male, elitist bias of legal precedent, and shift to a feminist juriprudence, the replacement of human lawyers with AI is still a technology that should be questioned either way.</p>
<p><a target="_blank" href="https://www.tandfonline.com/doi/abs/10.1080/13600834.1995.9965709?needAccess=true&amp;instName=McGill+University&amp;journalCode=cict20">Link to open access article</a></p>
<p class="tags"><label>Article</label><label>Law</label><label>Feminist Theoretical Perspective</label><label>Gender</label><label>AI</label><label>Artificial Intelligence</label><label>Expert Systems</label><label>Male Bias</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Technologies of the Gendered Body: Reading Cyborg Women</h1>
<h2>Anne Balsamo</h2>
<h3>1996</h3>
</header>
<div class="content">
<p>"This book takes the process of "reading the body" into the fields at the forefront of culture—the vast spaces mapped by science and technology—to show that the body in high-tech is as gendered as ever. From female body building to virtual reality, from cosmetic surgery to cyberpunk, from reproductive medicine to public health policies to TV science programs, Anne Balsamo articulates the key issues concerning the status of the body for feminist cultural studies in a postmodern world." <em>Quoted from publisher</em></p>
<p><a target="_blank" href="https://www.dukeupress.edu/technologies-of-the-gendered-body">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Technology Studies</label><label>Gender</label><label>Cyborg</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Cyberfeminism With a Difference</h1>
<h2>Rosi Braidotti</h2>
<h3>1996</h3>
</header>
<div class="content">
<p>This chapter theorizes the postmodern direction which feminists who challenge late-capitalism, and society as technology rises as a means of surveillance, are taking in order to envisage a new and different reality separate from the self-preservationalist goals of late-capitalism.   That being, "minor" genres of fiction such as science fiction but in particular, cyber punk, which demonstrate the ruptures in a seemingly inevitable world and show that a different future may be possible.</p>
<p><a target="_blank" href="https://disabilitystudies.nl/sites/disabilitystudies.nl/files/beeld/onderwijs/cyberfeminism_with_a_difference.pdf">Link to Free Text</a></p>
<p class="tags"><label>book</label><label>chapter</label><label>postmodern</label><label>feminism</label><label>technology</label><label>surveillance</label><label>sciencefiction</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Wired Women: Gender and New Realities in Cyberspace</h1>
<h2>Lynn Cherny and Elizabeth Reba Weise</h2>
<h3>1996</h3>
</header>
<div class="content">
<p>A book featuring fifteen essays centred around gender bias in the computer industry. Provides a new perspective and literary interrogation to the "macho and nerdy" computer industry. "Some of the excitement and the technological breakthroughs that the Internet offers come through here, but the book lacks coherence and interpretation or analysis of what these anecdotal contributions really signify" <em>Quoted from Library Journal revew on Amazon page</em></p>
<p><a target="_blank" href="https://www.amazon.ca/Wired-Women-Gender-Realities-Cyberspace/dp/1878067737">Link to Amazon page</a></p>
<p class="tags"><label>Book</label><label>Gender</label><label>Computing</label><label>Internet</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Bias in Computer Systems</h1>
<h2>Batya Friedman and Hellen Nissenbaum</h2>
<h3>1996</h3>
</header>
<div class="content">
<p>This article reviews what kinds of bias computer systems may have - including preexisting, technical and emergent bias - and comprehensively reviews the phenomenon of bias to offer a framework for remedying it. The authors suggest that freedom from bias should be counter among other criteria including reliability, accuracy and efficiency according to which the quality of systems in use in society should be judged.</p>
<p><a target="_blank" href="https://nissenbaum.tech.cornell.edu/papers/biasincomputers.pdf">Link to Text</a></p>
<p class="tags"><label>article</label><label>bias</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Boys and Their Toys: The Fisher Body Craftsman’s Guild, 1930–1968, and the Making of a Male Technical Domain.</h1>
<h2>Ruth Oldenziel</h2>
<h3>1997</h3>
</header>
<div class="content">
<p>Traces the male-centric dynamic of technology all the way back to the 20's - where the Fisher Body Divison (of General Motors) advertised model car building competitions and other adverts towards young/teen boys exclusively, and included girls in the ads gawking at the male's inventions.  Thus, the narrative that women have to somehow self-conpensate for the failure of not being more represented in tech is challenged, and traced back as far as the 1920's, were technology was already seen as something that men created, and women enjoyed.</p>
<p><a target="_blank" href="https://www.semanticscholar.org/paper/Boys-and-Their-Toys%3A-The-Fisher-Body-Craftsman%27s-of-Oldenziel/143af0e35b5c8d3613573ddad5df9dd24fde803e">Link to Free Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>technology</label><label>women</label><label>feminism</label><label>media</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Zeros + Ones: Digital Women and the New Technoculture</h1>
<h2>Sadie Plant</h2>
<h3>1997</h3>
</header>
<div class="content">
<p>"A highly contentious, very readable and totally up-to-the-minute investigation of women’s natural relationship with modern technology, an association which, Plant argues, will trigger a new sexual revolution.</p>
<p>Zeros and Ones is an intelligent, provocative and accessible investigation of the intersection between women, feminism, machines and in particular, information technology. Arguing that the computer is rewriting the old conceptions of man and his world, it suggests that the telecoms revolution is also a sexual revolution which undermines the fundamental assumptions crucial to patriarchal culture. Historical, contemporary and future developments in telecommunications and in IT are interwoven with the past, present and future of feminism, women and sexual difference, and a wealth of connections, parallels and affinities between machines and women are uncovered as a result. Challenging the belief that man was ever in control of either his own agency, the planet, or his machines, this book argues it is seriously undermined by the new scientific paradigms emergent from theories of chaos, complexity and connectionism, all of which suggest that the old distinctions between man, woman, nature and technology need to be radically reassessed." <em>Quoted from publisher</em></p>
<p><a target="_blank" href="https://www.harpercollins.com/products/zeros-and-ones-digital-women-and-the-new-technoculture-sadie-plant?variant=32173198573602">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Technology Studies</label><label>Sexuality</label><label>Gender</label><label>Feminism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Artificial Knowing : Gender and the Thinking Machine</h1>
<h2>Alison Adam</h2>
<h3>1998</h3>
</header>
<div class="content">
<p>"Artificial Knowing challenges the masculine slant in the Artificial Intelligence (AI) view of the world. Alison Adam admirably fills the large gap in science and technology studies by showing us that gender bias is inscribed in AI-based computer systems. Her treatment of feminist epistemology, focusing on the ideas of the knowing subject, the nature of knowledge, rationality and language, are bound to make a significant and powerful contribution to AI studies." Draws from feminist epistemology, Donna Haraway and Sherry Turkle specifically, to critique AI during the period when technology seemed like a great new horizon. <em>Quotation taken from publisher summary</em></p>
<p><a target="_blank" href="https://www.routledge.com/Artificial-Knowing-Gender-and-the-Thinking-Machine/Adam/p/book/9780415129633">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Artificial Intelligence</label><label>Metaphysics</label><label>Gender</label><label>Cyberfeminism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Meaning and Identity in “Cyberspace”: The Performance of Gender, Class, and Race Online</h1>
<h2>Lori Kendall</h2>
<h3>1998</h3>
</header>
<div class="content">
<p>The author conducted research on online forums which shows that while many people believe in continuity between their real life and online racial, gender and class identities, some people distanced themselves from their offline interpretations of these identities.  The thesis of the article is that online identities are performances that need be examined as separate from offline identities.</p>
<p><a target="_blank" href="https://onlinelibrary.wiley.com/doi/pdf/10.1525/si.1998.21.2.129?casa_token=eeEoCaSc3WoAAAAA:I_tlU4N8G0CnFvMvvBvsRrQiaUcYK3JlX8B4X_taINzhY_6pfZ-BYHoeBdCPISpwitEM89ik9Xii7jc">Link to Text</a></p>
<p class="tags"><label>article</label><label>race</label><label>gender</label><label>class</label><label>performatism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Reading Race Online</h1>
<h2>Byron Burkhalter</h2>
<h3>1999</h3>
</header>
<div class="content">
<p>Burkhalter examines how race, previously seen as a phenotypical physical trait, has carried on into the cybersphere although not based on appearance, but based on perspective, self-identification and voice. He looks into so-called "soc.culture" groups in which self-identified racial bodies continue conversations surrounding their race sans body, and the undisputableness of race is carried on into the internet.</p>
<p><a target="_blank" href="https://www-taylorfrancis-com.proxy3.library.mcgill.ca/books/edit/10.4324/9780203194959/communities-cyberspace-peter-kollock-marc-smith">Link to Text</a></p>
<p class="tags"><label>bookchapter</label><label>race</label><label>cyberculture</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Women and Internet: Creating New Cultures in Cyberspace</h1>
<h2>Wendy Harcourt</h2>
<h3>1999</h3>
</header>
<div class="content">
<p>"This is a major analysis of the emerging cultural characteristics of women's activities on the internet across the globe. It brings together anthropologists, communications experts, development workers and media analysts and women's movement activists to ask: are women caught in the net or weaving it themselves?</p>
<p>The book maps both the social, economic and political biases in which the culture of cyberspace is embedded as well its revolutionary potential, explores women's knowledge of and access to the Internet across the world, and puts forward concrete proposals for increasing women's engagement with the new communication technologies." <em>Quoted from publisher</em></p>
<p><a target="_blank" href="https://www.bloomsbury.com/us/womeninternet-9781856495721/">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Gender</label><label>Internet</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Cyberfeminism: Connectivity, Critique and Creativity</h1>
<h2>Susan Hawthorne and Renate Klein (eds)</h2>
<h3>1999</h3>
</header>
<div class="content">
<p>"This collection explores what the possibilities are for feminists and for feminism in cyberspace. It also grapples with pitfalls of the medium, with theorists examining trafficking of women, perceptions of the body, the discourses of the medium and the problems of global and homogenised culture. The book also includes discussions of cyberpoetry and hypertext, developing resources for online Women's Studies and libraries, as well as developments in CD-ROM, games and VRML." </p>
<p><a target="_blank" href="https://monoskop.org/images/e/e7/Hawthorne_Susan_Klein_Renate_eds_Cyberfeminism_Connectivity_Critique_and_Creativity_1999.pdf">Link to Text</a></p>
<p class="tags"><label>book</label><label>feminism</label><label>cyberfeminism</label><label>electronicactivism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>When Computers Were Women</h1>
<h2>Jennifer S. Light</h2>
<h3>1999</h3>
</header>
<div class="content">
<p>Looks at how 200 women supported the project of developping America's first electric computer during World War II, often credited to two men.  Furthermore analyzes how women's contribution to the early stages of computer history is occluded even if working in computer science truly stemmed from women's clerical labour, and how women's labour during wartime is often characterized as subproffesional, menial, and feminized.</p>
<p><a target="_blank" href="https://www.jstor.org/stable/25147356">Link to article with institutional access</a></p>
<p class="tags"><label>Article</label><label>Gender</label><label>Computing</label><label>History</label><label>Labour</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Making Technology Masculine: Men, Women, and Modern Machines in America 1985-1940</h1>
<h2>Ruth Oldenziel</h2>
<h3>1999</h3>
</header>
<div class="content">
<p>Text which situates the masculine-ness of technology in the pre-computer era, from the late Victorian era to the Second World War.  The book "maps the historical process through which men laid claims to technology as their exclusive terrain. It also explores how women contested this ascendancy of the male discourse and engineered alternative plots"</p>
<p><a target="_blank" href="https://www.jstor.org/stable/j.ctt46mtdk">Link to book</a></p>
<p class="tags"><label>Book</label><label>History</label><label>Gender</label><label>Technology Studies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Practices for Machine Culture: A Case Study of Integrating Cultural Theory and Artificial Intelligence</h1>
<h2>Phoebe Sengers</h2>
<h3>1999</h3>
</header>
<div class="content">
<p>Discusses why it is necessary for artifical intelligence developpers to consider not only what can be done, but what should be done, and what is best for society.  There has been a history of cultural scholars/critics interested in artifical intelligence's effect on society, as well as a history of artificial intelligence scientists stressing the important of cultural impact and criticism.  However, these ideas remain limited in the field at large, and should be employed more liberally.</p>
<p><a target="_blank" href="http://www.cs.cmu.edu/afs/cs/usr/phoebe/mosaic/work/papers/surfaces99/sengers.practices-machine-culture.html">Link to full article</a></p>
<p class="tags"><label>Article</label><label>AI</label><label>Artificial Intelligence</label><label>Cultural Studies</label><label>Cultural Theory</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Shaping the Web: Why the Politics of Search Engines Matters</h1>
<h2>Lucas D. Itrona and Helen Nissenbaum</h2>
<h3>2000</h3>
</header>
<div class="content">
<p>"This article argues that search engines raise not merely technical issues but also political ones. Our study of search engines suggests that they systematically exclude (in some cases by design and in some accidentally) certain sites, and certain types of sites, in favor of others, systematically give prominence to some at the expense of others.  We argue that such biases, which would lead to a narrowing of the Web’s functioning in society, run counter to the basic architecture of the Web as well as the values and ideals that have fueled widespread support for its growth and development. We consider ways of addressing the politics of search engines, raising doubts whether, in particular, the market mechanism could serve as an acceptable corrective."</p>
<p><a target="_blank" href="https://nissenbaum.tech.cornell.edu/papers/searchengines.pdf">Link to Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>internet</label><label>bias</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Race in Cyberspace</h1>
<h2>Beth Kolko, Lisa Nakamura and Gilbert Rodman (editors)</h2>
<h3>2000</h3>
</header>
<div class="content">
<p>Collection of essays which deal with a broad range of topics surrounding race and cyberspace, including how ethnicity and language revitalization are enacted in cyberspace, racial inequalities vis a vis technology, race-critical readings of films and videogames and virtual interactive cyberspaces. Written in 2000, relatively early in the history of the internet.</p>
<p><a target="_blank" href="https://www.routledge.com/Race-in-Cyberspace/Kolko-Nakamura-Rodman/p/book/9780415921633">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Cyberspace</label><label>Race</label><label>Ethnic Studies</label><label>Media Studies</label><label>Internet</label><label>Cultural Studies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Culture, Communication, and An Information Age Madonna</h1>
<h2>Jamie Hutchinson</h2>
<h3>2001</h3>
</header>
<div class="content">
<p>This piece explains the history of how an image of Lena Sjööblom, a model who was on the centrefold of Playboy Magazine in 1973, became an icon and baseline image for photocopying technologies for over three decades (without her, or playboys permission).  The researchers developping what would become jpeg and mpeg formats at USC used her image surreptitiously in the lab and it was thusly printed in tech magazines, displayed as demonstration of the technology, etc.  Demonstrates how copyright infringement and pornography, as well as the gendered dynamics of tech, have long been a part of the industry and development of imaging technology.</p>
<p><a target="_blank" href="http://www.lenna.org/pcs_mirror/may_june01.pdf">Link to piece</a></p>
<p class="tags"><label>Newsletter</label><label>Newspaper/Magazine</label><label>Gender</label><label>Technology Studies</label><label>Pornography</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Cybertypes: Race, Ethnicity, and Identity on the Internet</h1>
<h2>Lisa Nakamura</h2>
<h3>2002</h3>
</header>
<div class="content">
<p>Critical examination of the period proceeding the "Internet Age" (1994-2001), when the invention of the internet sparked ideations about post-national, post-racial equal space of the internet, when that sort of fascination was essentially shattered.  Since then, there is an idea that if you aren't on board with the internet, you are being left behind.. while in fact those being left behind are implicitly people of colour.  Looks at how the internet has posed new racial problems, in the tech industry (such as supposed "diversity" with East Asians but exclusion of Black people) and in online spaces. Written in 2002, so this is somewhat of a historical academic text about the internet.</p>
<p><a target="_blank" href="https://www.routledge.com/Cybertypes-Race-Ethnicity-and-Identity-on-the-Internet/Nakamura/p/book/9780415938372">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Race</label><label>Internet</label><label>Diversity</label><label>Inclusion</label><label>Cultural Studies</label><label>Media Studies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Cyberfeminism and Artifical Life</h1>
<h2>Sarah Kember</h2>
<h3>2003</h3>
</header>
<div class="content">
<p>This book examines how the concept of life as information has changed the way in which we culturally perceive our own lives, be it through cloning, computer games and technologies into our day to days which connect us to information systems.</p>
<p><a target="_blank" href="https://monoskop.org/images/8/87/Kember_Sarah_Cyberfeminism_and_Artificial_Life_2003.pdf">Link to Free Text</a></p>
<p class="tags"><label>book</label><label>AI</label><label>technology</label><label>computer</label><label>feminism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Silicon Valley, Women, and the California Dream : Gender, Class, and Opportunity in the Twentieth Century /</h1>
<h2>Glenna Matthews</h2>
<h3>2003</h3>
</header>
<div class="content">
<p>"What accounts for the growing income inequalities in Silicon Valley, despite huge technological and economic strides? Why have the once-powerful labor unions declined in their influence? How are increasing waves of immigration and ethnic diversity changing the workplace in the Valley? Silicon Valley, Women, and the California Dream examines these questions from a fresh perspective: that provided by the history of women in Silicon Valley in the twentieth century." <em>Quoted from book summary</em></p>
<p><a target="_blank" href="https://www.sup.org/books/title/?id=1432">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Computing</label><label>Silicon Valley</label><label>Class</label><label>Immigration</label><label>History</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Supply Side of the Digital Divide: Is There Equal Availability in the Broadband Internet Access Market?</h1>
<h2>James Prieger</h2>
<h3>2003</h3>
</header>
<div class="content">
<p>"The newest dimension of the digital divide is access to broadband (high-speed) Internet service. Using comprehensive U.S. data covering all forms of access technology (chiefly DSL and cable modem), I look for evidence of unequal broadband availability in areas with high concentrations of poor, minority, or rural households. There is little evidence of unequal availability based on income or on black or Hispanic concentration. There is mixed evidence concerning availability based on Native American or Asian concentration. Other findings: Rural location decreases availability; market size, education, Spanish language use, commuting distance, and Bell presence increase availability" <em>Quoted from abstract</em></p>
<p><a target="_blank" href="https://onlinelibrary.wiley.com/doi/abs/10.1093/ei/cbg013">Link to full article with institutional access</a></p>
<p class="tags"><label>Article</label><label>Accessibility</label><label>Broadband internet</label><label>Internet</label><label>Economic Inequality</label><label>Digital Divide</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Located Accountabilities in Technology Production</h1>
<h2>Lucy Suchman</h2>
<h3>2003</h3>
</header>
<div class="content">
<p>Inspried by Donna Haraway's "Situated Knowledges," this essay looks at how the production of technology should move away from so-called objectivity, "the view from nowhere," and instead take up located accountability, and employ feminist methodology particularly in the working relations of technological production.</p>
<p><a target="_blank" href="https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1082&amp;context=sjis">Link to article</a></p>
<p class="tags"><label>Article</label><label>Objectivity</label><label>Technology Studies</label><label>Feminist Methodology</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Can Compute, Won’t Compute: Women’s Participation in the Culture of Computing</h1>
<h2>Fiona Wilson</h2>
<h3>2003</h3>
</header>
<div class="content">
<p>First part of the paper gives secondary commentary on how the male-dominated computing industry is created by the stereotype that tech is aligned with masculine traits, ie. hard, linear, single-minded, which makes women feel like they can't be a part of that industry. Research study which qualitatively and quantitatively examines the gendered dynamics in a first year undergraduate Computer Science course -- questionnaires and informal interviews.  Other than the clear overrepresentation of males in the class and the computer science faculty, girls were less likely to have access to a computer in university, felt like they were less adept with the comptuer than their peers, etc.</p>
<p><a target="_blank" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-005X.00115">Link to article</a></p>
<p class="tags"><label>Computing</label><label>Article</label><label>Gender</label><label>Industry</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Cyberfeminism: Next Protocols</h1>
<h2>Edited by Claudia Reiche and Verena Kuni</h2>
<h3>2004</h3>
</header>
<div class="content">
<p>.... "this collection draws from art, theory and activism to explore the dominance of the digital medium and test its capacities to subvert cultural practices. Verena Kuni, Elisabeth Stadwick, Anne-Marie Schleiner and others attempt to critically analyze and define cyberfeminism through a variety of scientific observations and, in doing so, attempt to recreate the ideas of gender discreetly interwoven in the modernity of these digital times."</p>
<p><a target="_blank" href="https://books.google.ca/books/about/Cyberfeminism_Next_Protocols.html?id=vKGzAAAAIAAJ&amp;redir_esc=y">Link to Google Books</a></p>
<p class="tags"><label>Book</label><label>Cyberfeminism</label><label>Gender</label><label>Cultural Studies</label><label>Technology</label><label>Science</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Figures of Fantasy: Internet, Women, and Cyberdiscourse</h1>
<h2>Sussana Paasonen</h2>
<h3>2005</h3>
</header>
<div class="content">
<p>"Figures of Fantasy explores the popularization of the idea of the Internet as a «cyberspace» and considers the implications this has for discussions of gender and identity. The book analyzes the standard figures used to conceptualize and explain technology and gender, and traces the ways in which these concepts have served to create the figure of the Internet as a cyberspace – a manner of thinking that has come to dominate Internet research internationally, making visible its historicity, limitations, and implications." <em>Quoted from Amazon</em></p>
<p><a target="_blank" href="https://www.amazon.ca/Figures-Fantasy-Internet-Women-Cyberdiscourse/dp/0820476072">Link to Amazon</a></p>
<p class="tags"><label>Book</label><label>Gender</label><label>History</label><label>Cyberspace</label><label>Internet</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>"""BTW: How Do You Wear Your Hair?”: Gender and Race in Computer-mediated Hair Debates" in "From the Kitchen to the Parlor: Language and Becoming in African American Women's Hair Care," Oxford University Press</h1>
<h2>Lanita Jacobs-Huey</h2>
<h3>2006</h3>
</header>
<div class="content">
<p>"Based on insights gleaned from a two-month Internet debate about African American hair and identity politics, this chapter illustrates how gender and race come into play in black women's political claims about hair. [...] In Internet discussions, the participants' references to hairstyle and texture became an explicit means of constructing racial identity and authenticity (ie. natural or not, straightened or not, hair care regimen). The question “BTW [By the way], how do you wear your hair?” was an indirect way of assessing a speaker's ethnic identity and presumed racial consciousness vis-a-vis their hairstyle choices." <em>Quoted from abstract</em></p>
<p><a target="_blank" href="https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780195304169.001.0001/acprof-9780195304169">Link to book, available with institutional access</a></p>
<p class="tags"><label>Book Chapter</label><label>Article</label><label>Race</label><label>Black Femininity</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Disability Divide in Internet Access and Use</h1>
<h2>Eszter Hargittai and Kerr Dobransky</h2>
<h3>2006</h3>
</header>
<div class="content">
<p>This article researches people with disabilities relation to the internet, in terms of how many are using it and how the internet can both be helpful for some and inaccessible for other people with disabilities. A significant finding in the article is that low-income people with disabilities are less likely to have access to a computer and the internet, but those who have stable socioeconomic status do not use it less than able-bodied counterparts.</p>
<p><a target="_blank" href="http://webuse.org/p/a18/">Link to Free Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>internet</label><label>diability</label><label>access</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Using the Technology Acceptance Model to Explain How attitudes Determine Internet Usage: The Role of Perceived Access Barriers and Demographics</h1>
<h2>Constance Elise Porter and Naveen Donthu</h2>
<h3>2006</h3>
</header>
<div class="content">
<p>"Despite the fact that most Americans use the Internet, those who are older, less educated, minority and lower income have lower usage rates than younger, highly educated, white and wealthier individuals." The study analyzes why exactly this might be, and provide suggestions. Key insights: older people, lower income people and minorities know about the benefits of the internet, but due to cost, or inaccessibility, don't want to commit to it. <em>Quote taken from article abstract</em></p>
<p><a target="_blank" href="https://www.sciencedirect.com/science/article/abs/pii/S0148296306000993">Link to article, available with institutional access</a></p>
<p class="tags"><label>Article</label><label>Internet</label><label>Digital Divide</label><label>Inequality</label><label>Technology Acceptance Model</label><label>TAM</label><label>Internet Adoption</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>From Counterculture to Cyberculture: Stewart Brand, the Whole Earth Network, and the Rise of Digital Utopianism</h1>
<h2>Fred Turner</h2>
<h3>2006</h3>
</header>
<div class="content">
<p>This book explores the extraordinary and ironic transformation from when computers served as tools of the cold war, to when computers began to represent a  collaborative and digital utopia. Thanks to the vision of counterculturalists and technologists, computers were reimagined as tools for personal liberation, the building of virtual and decidedly alternative communities, and the exploration of bold new social frontiers. </p>
<p><a target="_blank" href="https://press.uchicago.edu/ucp/books/book/chicago/F/bo3773600.html">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Computing</label><label>History</label><label>Counterculture</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Social Network Sites: Definition, History, and Scholarship</h1>
<h2>danah m. boyd, Nicole B. Ellison</h2>
<h3>2007</h3>
</header>
<div class="content">
<p>This 2007 article provides "a conceptual, historical and scholarly context" for the disourse around social media networks which was in its nascent years during this time.</p>
<p><a target="_blank" href="https://academic.oup.com/jcmc/article/13/1/210/4583062?searchresult=1">Link to Free Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>social</label><label>network</label><label>history</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Stitch’nBitch: Cyberfeminism, a Third Place and the New Materiality</h1>
<h2>Stella Minahan and Julie Wolfram Cox</h2>
<h3>2007</h3>
</header>
<div class="content">
<p>This article looks at the Stitch'n'Bitch craft movement, in which women meet in person or online to knit, stitch and talk. Their presence is to be seen as a negative response to major political, social and technological changes such as globalization, terrorism, and damage to the environment. The authors discuss five themes to assist in research agenda development into material culture: remedial, progressive, rresistance, nostalgic, and ironic possibilities.</p>
<p><a target="_blank" href="https://journals-sagepub-com.proxy3.library.mcgill.ca/doi/10.1177/1359183507074559">Link to Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>cyberfeminisms</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Women in Computing: The Role of Geek Culture</h1>
<h2>Roli Varma</h2>
<h3>2007</h3>
</header>
<div class="content">
<p>"Geek culture," the high-tech, male centric subculture associated with computer science and engineering has been typified as a stigma preventing women from wanting to enter the field, according to research done at a majority white school.  Here, Varma, interviewed people from various minorities at other American schools to gauge how women of colour felt about the geek stereotype.  Overwhelmingly, WOC didn't mind the geek stereotype if it came with the job security of computer science, and replaced worse stereotypes they faced.  Thus, an intersectional study into the feelings of women about geek culture deepends the discourse.</p>
<p class="tags"><label>Article</label><label>Computing</label><label>Gender</label><label>Race</label><label>Education</label><label>Stereotypes</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>'Just Roll Your Mouse Over Me': Designing Virtual Women for Customer Service on the Web.</h1>
<h2>Sean Zdenek</h2>
<h3>2007</h3>
</header>
<div class="content">
<p>"This paper explores ... the tendency among designers to figure [animated software agents] as young women. While designers claim that animated/personified interfaces are more intuitive and natural than the traditional point-and-click interfaces that users encounter, this paper aims to show how virtual humans can enact familiar scripts about women's work, circumscribe the range of possible roles and personalities for women, invoke service to others as the primary context for women's work, and objectify women through a not-so-subtle process of linking technology-as-tool to the idea that women are tools, fetishized instruments to be used in the service of accomplishing users' goals" <em>Quoted from abstract</em></p>
<p><a target="_blank" href="https://www.tandfonline.com/doi/abs/10.1080/10572250701380766">Link to article</a></p>
<p class="tags"><label>Article</label><label>Virtual Assistants</label><label>Ethical Design</label><label>Customer Service</label><label>AI</label><label>Artificial Intelligence</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Health at High Speed: Broadband Internet Access, Health Communication, and the Digital Divide</h1>
<h2>Stephen A. Rains</h2>
<h3>2008</h3>
</header>
<div class="content">
<p>"The study reported here explored the broadband digital divide in the context of Internet-based health communication [...] Results showed that those who were younger, more educated, and lived in an urban area were more likely to have a broadband Internet connection in their home. Furthermore, consistent with the CMIS, those with a broadband connection were more likely to use the Internet for health-related information seeking and communication than those with a dial-up connection." <em>Quoted from abstract</em></p>
<p><a target="_blank" href="https://journals.sagepub.com/doi/10.1177/0093650208315958">Link to open access article</a></p>
<p class="tags"><label>Article</label><label>Accessibility</label><label>Health</label><label>Internet</label><label>Broadband</label><label>Digital Divide</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Inhibition of Geographical Information in Digital Humanities Scholarship</h1>
<h2>Martyn Jessop</h2>
<h3>2008</h3>
</header>
<div class="content">
<p>This article explores why the factor of geographical information systems in digital humanities has been inhibited by current research practices and the attitudes of scholarly institutions, despite being an essential part of digital humanity research.</p>
<p><a target="_blank" href="https://academic.oup.com/dsh/article-abstract/23/1/39/932267?redirectedFrom=fulltext">Link to Text</a></p>
<p class="tags"><label>article</label><label>digitalhumanities</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>An Impossible Future: John Perry Barlow's Declaration of the Independence of Cyberspace</h1>
<h2>Aim'ee Hope Morrison</h2>
<h3>2009</h3>
</header>
<div class="content">
<p>A critique of John Perry Barlow's "declaration of the independence of cyberspace' in which the internet will be the immanent site of revolution for its contradictions, misdirection and falsehoods and how it is now mocked as absurd. </p>
<p><a target="_blank" href="https://www.researchgate.net/publication/249689543_An_impossible_future_John_Perry_Barlow%27s_%27Declaration_of_the_Independence_of_Cyberspace%27">Link to Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>internet</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Quest for Artificial Intelligence: A History of Ideas and Achievements</h1>
<h2>Nils J. Nilson</h2>
<h3>2009</h3>
</header>
<div class="content">
<p>This book outlines historical narratives surrounding AI. I do not think it does a lot to address issues of race or gender."
"This book promises to be the definitive history of a field that has captivated the imaginations of scientists, philosophers, and writers for centuries" Thus, might be useful to understand the hegemonic historical narratives of AI.</p>
<p><a target="_blank" href="https://ai.stanford.edu/~nilsson/QAI/qai.pdf">Link to open access book</a></p>
<p class="tags"><label>Book</label><label>AI</label><label>Artificial Intelligence</label><label>History</label><label>Gender</label><label>Race</label><label>Narratives</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Cultural Appropriations of Technical Capital: Black women, weblogs, and the digital divide</h1>
<h2>André Brock, Lynette Kvasny &amp; Kayla Hales</h2>
<h3>2010</h3>
</header>
<div class="content">
<p>This paper uses the framework of cultural and technical capital to explore how information and communication technologies reframes Black women's ability to have conversations about their personal experiences, their takes on racism and sexism, arguments about black women's beauty and calue aka their vision of Black womanhood in web spaces that were preluded by in-person settings such as beauty salons. Argues against the deficit models of minority access to information technology.</p>
<p><a target="_blank" href="https://www.are.na/block/3130860">Link to Free Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>technology</label><label>digital</label><label>racism</label><label>sexism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Issues in Publishing an Online, Open-Access CALL Journal</h1>
<h2>Dorothy M Chun and Irene Thompson</h2>
<h3>2010</h3>
</header>
<div class="content">
<p>The editors in chief of an open-access, 100% online publication discuss the pros and cons of online journals.  Briefly, the advantages are the broad dissemination, access and efficiency, disadvantages are assumed lesser quality, opinions that these articles are less worthy for tenure and promotion. Digital journals are becoming more popular due to its pros, and its cons can be addressed as universities begin to recognize the importance of web-based open access journals.</p>
<p><a target="_blank" href="https://www.researchgate.net/publication/275612826_Open_Access_Journals_What's_the_Problem">Link to Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>open-access</label><label>onlinejournals</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Feminist Technology</h1>
<h2>Linda L. Layne, Sharra L. Vostral, and Kate Boyer</h2>
<h3>2010</h3>
</header>
<div class="content">
<p>In this collection, feminist scholars consider the question of what makes a technology feminist by examining a range of products, tools, and technologies specifically designed for and marketed to women. "Evaluating the claims that such products are liberating for women, the contributors focus on case studies of menstrual-suppressing birth control pills, home pregnancy tests, tampons, breast pumps, Norplant, anti-fertility vaccines, and microbicides. In examining these various products, this volume explores ways of actively intervening to develop better tools for designing, promoting, and evaluating feminist technologies." <em>Quoted from publisher</em></p>
<p><a target="_blank" href="https://www.press.uillinois.edu/books/catalog/53phf3qw9780252035326.html">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Technology Studies</label><label>Gender</label><label>Feminism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Why So Few Women Enroll in Computing? Gender and Ethnic Differences in Students’ Perception</h1>
<h2>Roli Varma</h2>
<h3>2010</h3>
</header>
<div class="content">
<p>"This article examines the reasons behind low enrollment of women in CS/CE education at institutions of higher education. It is based on 150 in-depth interviews of female and male undergraduate students majoring in CS/CE, members of five major ethnic groups from seven Minority-Serving Institutions in the USA. The article finds bias in early socialization and anxiety toward technology as two main factors responsible for the under-representation of women in CS/CE education. It further shows significant gender and ethnic differences in students' responses on why so few women enroll in CS/CE." <em>Quoted from abstract</em></p>
<p><a target="_blank" href="https://www.tandfonline.com/doi/abs/10.1080/08993408.2010.527697">Link to full article</a></p>
<p class="tags"><label>Article</label><label>Computing</label><label>Gender</label><label>Race</label><label>Education</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Affect &amp; Artificial Intelligence</h1>
<h2>Elizabeth A. Wilson</h2>
<h3>2010</h3>
</header>
<div class="content">
<p>Wilson shows "that early researchers were more engaged with questions of emotion than many commentators have assumed. She documents how affectivity was managed in the canonical works of Walter Pitts in the 1940s and of Turing in the 1950s," all the way into the 90's." "In this fresh and provocative contribution to affect studies, Elizabeth Wilson convincingly argues that from its beginnings the theory and practice of artificial intelligence has been decisively marked by feelings---surprise, curiosity, delight, shame, and contempt---as well as computational logic."</p>
<p><a target="_blank" href="https://uwapress.uw.edu/book/9780295990477/affect-and-artificial-intelligence/">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Artificial Intelligence</label><label>AI</label><label>Affect</label><label>Feminist Theory</label><label>Affect Studies</label><label>Technology Studies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>A Need for Speed? Rural Internet Connectivity and the No Access/ Dial-Up/High-Speed Decision</h1>
<h2>Brian E. Whitacre and Bradford F. Mills</h2>
<h3>2010</h3>
</header>
<div class="content">
<p>This article uses a nested logit model to explore the household decision between no Internet access, dial-up access and high-speed access. A decomposition technique is then used to estimate the contributions of various factors, including education, income and infrastructure levels, to differences in Internet access among rural and urban households. The results suggest that policies which solely promote infrastructure in rural areas fail to address the dominant factors in the emerging high-speed digital divide.</p>
<p><a target="_blank" href="https://ideas.repec.org/p/ags/aaea06/21272.html">Link to article</a></p>
<p class="tags"><label>Article</label><label>Internet</label><label>Digital Divide</label><label>Accessibility</label><label>Broadband</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>All the Digital Humanists Are White, All the Nerds Are Men, but Some of Us Are Brave</h1>
<h2>Moya Bailey</h2>
<h3>2011</h3>
</header>
<div class="content">
<p>Bailey intersectionally analyzes digital humanities scholarship, how women, poc, disability scholars are necessary to address the replicated power structures in digital humanities which foreground white, male ideas while erasing the contributions of others.</p>
<p><a target="_blank" href="http://journalofdigitalhumanities.org/1-1/all-the-digital-humanists-are-white-all-the-nerds-are-men-but-some-of-us-are-brave-by-moya-z-bailey/">Link to Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>digital</label><label>humanities</label><label>power</label><label>intersectionality</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Digital Dead End: Fighting for Social Justice in the Information Age</h1>
<h2>Virginia Eubanks</h2>
<h3>2011</h3>
</header>
<div class="content">
<p>Refutes the idea that technology will magically, economically and socially improve our world, since this idea is rooted in the neglect of poor and working class women and families, who technology is inclined to simultaneously help and oppress. "Eubanks describes a new approach to creating a broadly inclusive and empowering “technology for people,” <em>popular technology</em>, which entails shifting the focus from teaching technical skill to nurturing critical technological citizenship, building resources for learning, and fostering social movement." <em>Quote from book summary</em></p>
<p><a target="_blank" href="https://mitpress.mit.edu/books/digital-dead-end">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Technology</label><label>Marxism</label><label>Cultural Studies</label><label>Economics</label><label>Popular Technology</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Intersecting Oppressions and Online Communities: Examining the experiences of women of color in Xbox Live</h1>
<h2>Kishonna L. Gray</h2>
<h3>2011</h3>
</header>
<div class="content">
<p>This paper is on the oppressions experienced by WOC in the online gaming community Xbox Live and employs qualitative methods, ethnography, and an intersectional framework.  Since the game can involve speaking in an online room with other players on your team, Latina and African-American women are linguistically profiled for their gender and sometimes sexuality by the way they sound, especially in the context where people hide behind their screens and have little to no consequences for what they say.  This has led to women segregating from these larger communities and creating their own spaces.</p>
<p><a target="_blank" href="https://doi.org/10.1080/1369118X.2011.642401">Link to open access article</a></p>
<p class="tags"><label>Article</label><label>Race</label><label>Gender</label><label>identity</label><label>Gaming</label><label>Internet</label><label>Online Communities</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Reducing Barriers to Online Access for People with Disabilities</h1>
<h2>Paul Jaegar and Jonathan Lazar</h2>
<h3>2011</h3>
</header>
<div class="content">
<p>The article focuses on the online access of Internet for people with disabilities in the U.S. It states that most Internet-related technologies are inaccessible to disabled people because of the Internet access policy which is considered to reject the needs of disabled people. It adds that solving limited compatibility of Web content is the challenge facing online access for visually impaired people, while the lack of interactive Web chats is the problem associated with hearing impaired people.</p>
<p><a target="_blank" href="https://go-gale-com.proxy3.library.mcgill.ca/ps/retrieve.do?tabID=Journals&amp;resultListType=RESULT_LIST&amp;searchResultsType=MultiTab&amp;hitCount=1&amp;searchType=AdvancedSearchForm&amp;currentPosition=1&amp;docId=GALE%7CA246949286&amp;docType=Article&amp;sort=Relevance&amp;contentSegment=ZEES-MOD1&amp;prodId=GRNR&amp;pageNum=1&amp;contentSet=GALE%7CA246949286&amp;searchId=R1&amp;userGroupName=crepuq_mcgill&amp;inPS=true">Link to Text</a></p>
<p class="tags"><label>article</label><label>disability</label><label>accessibility</label><label>internet</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Revisiting Cyberfeminism</h1>
<h2>Susanna Paasonen</h2>
<h3>2011</h3>
</header>
<div class="content">
<p>This academic article examines the concept of <em>Cyberfeminism</em>, from a historical perspective.  Paaronen explains how the term "cyberspace" was momentarily popular in the 1990's and is no longer popular now.  Thus, cyberfeminism was a historical moment where the possibilities of the internet in its nascent form attracted feminists and others as a realm of possibility, where cyberspace was disembodied from our realities, an idea which has not lasted since today, our online personnas are connected to our real lives.  Thus, the future of feminism on the internet may be inspired by this history but will look different depending on how feminists interact with cyberculture.</p>
<p><a target="_blank" href="https://www.arifyildirim.com/ilt510/susanna.paasonen.pdf">Link to full article</a></p>
<p class="tags"><label>article</label><label>cyberfeminism</label><label>gender</label><label>new technology</label><label>feminism</label><label>networks</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Fatal Invention: How Science, Politics, and Big Business Re-create Race in the Twenty-first Century</h1>
<h2>Dorothy E. Roberts</h2>
<h3>2011</h3>
</header>
<div class="content">
<p>Looks at how the myth of race being biologically determined rather than socially constructed has been revived by technologies such as edge science, race-specific drugs, genetic testing, and DNA databases.  The myth of the post-racial society is thus challenged directly by Roberts analysis and shown that racism is still pervasive and thriving.</p>
<p><a target="_blank" href="https://www.scribd.com/book/387782841/Fatal-Invention-How-Science-Politics-and-Big-Business-Re-create-Race-in-the-Twenty-First-Century">Free Text Preview</a> <a target="_blank" href="https://thenewpress.com/books/fatal-invention">Full Text, No Free Text Available</a></p>
<p class="tags"><label>book</label><label>race</label><label>technology</label><label>science</label><label>DNA</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>White Flight in Networked Publics? How Race and Class Shaped American Teen Engagement with MySpace and Facebook</h1>
<h2>danah boyd</h2>
<h3>2012</h3>
</header>
<div class="content">
<p>Analyzes the so-called white flight of white and white-adjacent teens from MySpace to Facebook in 2006-7 era when MySpace was dominant and Facebook was nascent.  Ideas that Myspace was becoming a place that was "more ghetto" or "for those who like hip hop/rap," teens drew racial boundaries and showed that the shift to Facebook was based in racial undertones of feeling like black culture and people were overpopulating MySpace and thus "fleeing" for Facebook.</p>
<p><a target="_blank" href="https://www.danah.org/papers/2009/WhiteFlightDraft3.pdf">Link to text</a></p>
<p class="tags"><label>bookchapter</label><label>race</label><label>internet</label><label>socialmedia</label><label>whiteflight</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Technology for People, Not Disabilities: Ensuring Access and Inclusion</h1>
<h2>Alan Foley and Beth A. Ferri</h2>
<h3>2012</h3>
</header>
<div class="content">
<p>This article proposes alternative ways of thinking about inclusivity and accessibility, in regards to technology which is created to help people with disabilities.  If these technologies are reconceptualized as global, accessible and inclusive to everyone, this would allow for greater acess and flexibility for all people on the disability spectrum.</p>
<p><a target="_blank" href="https://www.researchgate.net/publication/263752183_Technology_for_people_not_disabilities_Ensuring_access_and_inclusion">Link to free text</a></p>
<p class="tags"><label>article</label><label>disability</label><label>accesibility</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Net Delusion: How Not to Liberate the World</h1>
<h2>Evgeny Morozov</h2>
<h3>2012</h3>
</header>
<div class="content">
<p>This book challenges the idea that the internet is a place of freedom and revolt since authoritarian governments are actually able to use the internet to stabilize and repress.  The idea of internet freedom is therefore misguided and harmful.</p>
<p><a target="_blank" href="https://ebookcentral.proquest.com/lib/mcgill/detail.action?docID=868978">Link to Text</a></p>
<p class="tags"><label>book</label><label>freedom</label><label>authoritarianism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Race After Internet</h1>
<h2>Lisa Nakamura and Peter Chow-White</h2>
<h3>2012</h3>
</header>
<div class="content">
<p>Collection of essays that study how racial topographies have crossed over to the internet rather than being eliminated like people once thought.  Includes topics such as Facebook and MySpace, YouTube and viral video, WiFi infrastructure, the One Laptop Per Child (OLPC) program, genetic ancestry testing, DNA databases in health and law enforcement, and popular online games like World of Warcraft, in conversation with race.  Explores how new technologies redefine and produce racial inequalities.</p>
<p><a target="_blank" href="https://www.routledge.com/Race-After-the-Internet/Nakamura-Chow-White/p/book/9780415802369?gclid=CjwKCAjwt8uGBhBAEiwAayu_9UISlPBQAAgw5saoKPOo9lp_Gt1zMdHUAXo21XugZD2Gi0slsroIoxoCNZoQAvD_BwE">Link to publisher site, no free text available</a></p>
<p class="tags"><label>Race</label><label>Internet</label><label>Anthology</label><label>Book</label><label>Social Media</label><label>Gaming</label><label>Racial inequality</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Digital Inclusion and Data Profiling</h1>
<h2>Seeta Peña Gangadharan</h2>
<h3>2012</h3>
</header>
<div class="content">
<p>"This paper examines specific examples of commercial data profiling against a longer history of low–tech data profiling of chronically underserved communities. It concludes by calling for issues of online privacy and surveillance to punctuate digital inclusion discourse. Until this happens, digital inclusion policies threaten to bring chronically underserved communities into online worlds that, as Gandy (2009) argued, reinforce and exacerbate social exclusion and inequalities." <em>Summary taken from abstract</em></p>
<p><a target="_blank" href="https://firstmonday.org/article/view/3821/3199">Link to Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>digital</label><label>data</label><label>discrimination</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Access/Impact Problem and the Green and Gold Roads to Open Access: An Update</h1>
<h2>Tim Brody, Les Carr, Yves Gingras, Chawki Hajjem, Steven Harnad, Eberhard R. Hilf, Steve Hitchcock, Charles Oppenheim, François Vallières</h2>
<h3>2013</h3>
</header>
<div class="content">
<p>This article analyzes the state of scholarly accesibility in 2013. 10% of articles are published directly to open-access journals, while the other 90% are given the green light to self-publish to open-access journals as well as non-OA publishers.  However, online 10-20% of articles have been self-archived, and the article surmises that self-archiving needs to be mandated as the next step towards full OA.</p>
<p><a target="_blank" href="https://www-tandfonline-com.proxy3.library.mcgill.ca/doi/full/10.1080/00987913.2008.10765150">Link to Text</a></p>
<p class="tags"><label>article</label><label>accessibility</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>“Gendertrolling: Misogyny Adapts to New Media</h1>
<h2>Karla Mantilla</h2>
<h3>2013</h3>
</header>
<div class="content">
<p>In this piece, Mantilla defines "gendertrolling," which was a relatively new phenomenon, in which people (in this case womxn) were victims of gender-based insults, viscious language and credible threats, and were made a target by numerous people, often coordinated for a long period of time. This happens in many online communities and targets outspoken women at large.</p>
<p><a target="_blank" href="https://www-jstor-org.proxy3.library.mcgill.ca/stable/23719068?seq=7#metadata_info_tab_contents">Link to Text</a></p>
<p class="tags"><label>article</label><label>gender</label><label>gendertrolling</label><label>onlineharassment</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Consent of the Networked: The Worldwide Struggle for Internet Freedom</h1>
<h2>Rebecca MacKinnon</h2>
<h3>2013</h3>
</header>
<div class="content">
<p>"In Consent of the Networked, journalist and Internet policy specialist Rebecca MacKinnon argues that it is time to fight for our rights before they are sold, legislated, programmed, and engineered away. Every day, the corporate sovereigns of cyberspace (Google and Facebook, among others) make decisions that affect our physical freedom -- but without our consent. Yet the traditional solution to unaccountable corporate behavior -- government regulation -- cannot stop the abuse of digital power on its own, and sometimes even contributes to it.</p>
<p>A clarion call to action, Consent of the Networked shows that it is time to stop arguing over whether the Internet empowers people, and address the urgent question of how technology should be governed to support the rights and liberties of users around the world." <em>Summary quoted from Amazon</em></p>
<p><a target="_blank" href="https://www.amazon.ca/Consent-Networked-Worldwide-Struggle-Internet/dp/0465063756">Link to Amazon</a></p>
<p class="tags"><label>Book</label><label>Industry</label><label>Internet</label><label>Inequality</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Discrimination in Online Ad Delivery</h1>
<h2>Latanya Sweeney</h2>
<h3>2013</h3>
</header>
<div class="content">
<p>This study examines how automated ads racially profile certain "black-sounding" names online when suggesting arrest records.  Ie. the author discovered when searching up her own name, Latanya Sweeney, ads that read "Latanya Sweeney, arrested?" showed up because of a) other cases of Latanya's being arrested and b) the fact that searching up the name in google images yields mostly black pictures.  Given that names such as Jill did not suggest such ads despite being present in arrest records, the study suggests that algorithms use the info of racially profiled names to suggest ads to look up the arrest histories of black people unfairly.</p>
<p><a target="_blank" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2208240">Link to Text</a></p>
<p class="tags"><label>article</label><label>study</label><label>algorithm</label><label>racial</label><label>profiling</label><label>discrimination</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Free is a Lie</h1>
<h2>Aral Balkan</h2>
<h3>2014</h3>
</header>
<div class="content">
<p>In this talk, Aral Balkan unpacks the misconception that "free" internet services such as Facebook and Google platforms come with no cost. He discusses data farming, and how our personal data has become the valuable commodity that comapnies are after in our increasingly surveilled, measured and mapped world.  In 2020, most of this talk is not shocking or new anymore but rather common knowledge.  However, i think that in 2014 this was probably a really fascinating talk.</p>
<p><a target="_blank" href="https://www.youtube.com/watch?v=69k-72xKnd4">Link to Video Lecture</a></p>
<p class="tags"><label>video</label><label>lecture</label><label>internet</label><label>data</label><label>farming</label><label>surveillance</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Why Women Aren't Welcome on the Internet</h1>
<h2>Amanda Hess</h2>
<h3>2014, updated 2017</h3>
</header>
<div class="content">
<p>This article about the author (a female journalist who "writes about sex") describes her experience being targeted with death threats, rape threats, doxxing and more. Hess explores how this is the standard experience for women who voice their opinions on the internet. Female-presenting usernames and accounts are disproportionately cyberbullied and targeted with sexually explicit and threatening messages compared to men. Hess also discusses the issue regarding jurisdiction for legal action regarding these threats, highlighting how law enforcement belittles these threats and redirects victims to Twitter, while Twitter redirects back to law enforcement.</p>
<p><a target="_blank" href="https://psmag.com/social-justice/women-arent-welcome-internet-72170">Link to Text</a></p>
<p class="tags"><label>article</label><label>cyberharassment</label><label>cyberbullying</label><label>internet</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Online Incivility or Sexual Harrassment? Conceptualising Women's Experiences in the Digital Age</h1>
<h2>Jessica Megarry</h2>
<h3>2014</h3>
</header>
<div class="content">
<p>This article looks into women's experiences online with sexual harassment specfically on Twitter (in 2014 when not much research had been done to-date), and how through the hashtag #mencallmethings, harassment is conveyed and shows how womens voices are excluded from the digital sphere.</p>
<p><a target="_blank" href="https://www-sciencedirect-com.proxy3.library.mcgill.ca/science/article/pii/S0277539514001332">Link to Text</a></p>
<p class="tags"><label>article</label><label>gender</label><label>sexualharassment</label><label>twitter</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Indigenous Circuits: Navajo Women and the Racialization of Early Electronic Manufacture</h1>
<h2>Lisa Nakamura</h2>
<h3>2014</h3>
</header>
<div class="content">
<p>Traces the history of Navajo women who were employed at a tech manufacturing plant from 1965-75. "In the face of concerns about high-tech pollution, increasingly empowered labor organizations, and a newly politicized and visible American Indian civil rights movement, indigenous electronic workers at Shiprock were pressed into service as examples of the peaceful coexistence and integration of the past and the future, the primitive and the modern, creativity and capitalism. Navajo women workers were described as ideal predigital digital workers, uniquely suited to the job by temperament, culture, and gender. Their labor as platform builders was cited as evidence that digital work—the work of the hand and its digits—could be painlessly transferred from the indigenous cultural context into the world of technological commercial innovation, benefiting both in the process" <em>Quoted from article abstract</em></p>
<p><a target="_blank" href="https://muse.jhu.edu/article/563663">Link to full article</a></p>
<p class="tags"><label>Article</label><label>Computing</label><label>Race</label><label>Indigenous</label><label>Electronics</label><label>Navajo</label><label>History</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Person-centered Accessible Technologies and Computing Solutions Through Interdisciplinary and Integrated Perspectives From Disability Research</h1>
<h2>Sethuraman Panchanathan and Troy McDaniel</h2>
<h3>2014</h3>
</header>
<div class="content">
<p>The authors introduce their own methodology to enrich "Human-centred multimedia computing" (HCMC), a subfield of computer science which leverages social and behaviour sciences to immprove the usages of technologies, by factoring in the persepctives of people with disabilities.  They theorize how an interdisciplinary approach, considering technology and design from a disability perspective can enrich the design of person-centred accessible technologies</p>
<p><a target="_blank" href="https://link.springer.com/article/10.1007/s10209-014-0369-9">Link to article</a></p>
<p class="tags"><label>Article</label><label>Disability</label><label>Technology</label><label>Design</label><label>Interdisciplinary</label><label>Computing</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The People's Platform: Taking Back Power and Culture in the Digital Age</h1>
<h2>Astra Taylor</h2>
<h3>2014</h3>
</header>
<div class="content">
<p>Addresses why the internet is not inherently liberatory, and in fact replicates most of the economic, racial etc. inequalities of the pre-internet era. "The online world does offer an unprecedented opportunity, but a democratic culture that supports diverse voices, work of lasting value, and equitable business practices will not appear as a consequence of technology alone. If we want the Internet to truly be a people's platform, we will have to make it so"</p>
<p><a target="_blank" href="https://www.penguinrandomhouse.ca/books/212898/the-peoples-platform-by-astra-taylor/9780307360342">Link to publisher site, no free text available</a></p>
<p class="tags"><label>Book</label><label>Internet Democracy</label><label>Media Studies</label><label>Social Media</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>New opportunities for Computer Vision-Based Assistive Technology Systems for the Visually Impaired</h1>
<h2>Juan R. Terven, Joaquín Salas, Bogdan Raducanu</h2>
<h3>2014</h3>
</header>
<div class="content">
<p>"Computing advances and increased smartphone use gives technology system designers greater flexibility in exploiting computer vision to support visually impaired users. Understanding these users’ needs will certainly provide insight for the development of improved usability of computing devices." Survey of the existing computer vision-based technologies in development and how developments in smart-phones and computer vision systems can help the visually impaired.</p>
<p><a target="_blank" href="http://www.cvc.uab.es/people/bogdan/Publications/raducanu_Computer2013.pdf">Link to Free Text</a></p>
<p class="tags"><label>article</label><label>disability</label><label>acessibility</label><label>technology</label><label>computer</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Cyber-Violence Against Women</h1>
<h2>Jessica West</h2>
<h3>2014</h3>
</header>
<div class="content">
<p>Literature review and research report on how women experience violence in cyberspace, how this sort of violence compares to physical abuse/sexual assault, and how it differs. Notably, anonymity, cyberstalking and appropriating womens images and writings are common forms. The vastness of the internet gives perpetrators a feeling of invincibility, yet also the internet's permanence makes cyber-violence different from offline forms.  How this violence impacts women's lives, how to resists and what the community can do etc. is discussed: more support from online platforms to address cyberviolence, tighter terms of use, legal reform so that women may take action, increasing awarenes, education and awareness campaigns, focusing on protecting young girls. The "get off the internet" approach is not sufficient to protect women from cyber-violence.</p>
<p><a target="_blank" href="https://www.bwss.org/wp-content/uploads/2014/05/CyberVAWReportJessicaWest.pdf">Link to full report</a></p>
<p class="tags"><label>Cyberviolence</label><label>article</label><label>Report</label><label>Gender</label><label>Gendered Violence</label><label>Internet</label><label>Online Harassment</label><label>Rape Culture</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Notes on the Political Condition of Cyberfeminism</h1>
<h2>Faith Wilding &amp; Critical Art Ensemble</h2>
<h3>2014</h3>
</header>
<div class="content">
<p>"The first part of this article is drawn from material originally posted on the Nettime and FACES listservs in the summer of 1997. The second part consists of excerpted e-mail dispatches (in italics) from the First Cyberfeminist International (CI) in Kassel. interspersed with short commentaries. It is intended as an example of evolving cyberfeminist practice. Since the CI was a collective action, and since not all of the presentations on the program could be discussed, no individuals' names have been attached to the presentations and workshops described here. Women on the women-only listserv FACES are called Faces. A full list of Faces who participated in the CI can be found at the end of this article." <em>Quoted from abstract</em></p>
<p><a target="_blank" href="https://www.tandfonline.com/doi/abs/10.1080/00043249.1998.10791878">Link to open access article</a></p>
<p class="tags"><label>Article</label><label>Cyberfeminism</label><label>Feminism</label><label>Gender</label><label>Information Technology</label><label>Art</label><label>Internet</label><label>Cultural Studies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1># transform (ing) DH Writing and Research: An Autoethnography of Digital Humanities and Feminist Ethics</h1>
<h2>Moya Bailey</h2>
<h3>2015</h3>
</header>
<div class="content">
<p>Bailey describes authoethnographically, the process of researching the hashtag #girlslikeus on twitter, to demonstrate how to ethically do digital humanities scholarship.  For example, collaborating online with the group you are writing about, getting permission and creating community which serves greater purpose than knowledge extraction.</p>
<p><a target="_blank" href="http://www.digitalhumanities.org//dhq/vol/9/2/000209/000209.html">Link to Text</a></p>
<p class="tags"><label>twitter</label><label>hashtag</label><label>digital</label><label>humanities</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Flash Forward Podcast</h1>
<h2>Rose Eveleth</h2>
<h3>2015 - present</h3>
</header>
<div class="content">
<p>"Flash Forward is a critically acclaimed podcast about the future. In each episode, host Rose Eveleth takes on a possible (or not so possible) future scenario — everything from the existence of artificial wombs, to what would happen if space pirates dragged a second moon to Earth. What would the warranty on a sex robot look like? How would diplomacy work if we couldn’t lie?" "...By combining audio drama and deep reporting, Flash Forward gives listeners an original and unique window into the future, how likely different scenarios might be, and how to prepare for what might come." <em>Quoted from website</em></p>
<p><a target="_blank" href="https://www.flashforwardpod.com">Link to podcast website</a></p>
<p class="tags"><label>Podcast</label><label>Futurity</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Dark Matters: On the Surveillance of Blackness</h1>
<h2>Simone Browne</h2>
<h3>2015</h3>
</header>
<div class="content">
<p>"Simone Browne locates the conditions of blackness as a key site through which surveillance is practiced, narrated, and resisted. She shows how contemporary surveillance technologies and practices are informed by the long history of racial formation and by the methods of policing black life under slavery, such as branding, runaway slave notices, and lantern laws. Placing surveillance studies into conversation with the archive of transatlantic slavery and its afterlife, Browne draws from black feminist theory, sociology, and cultural studies to analyze texts as diverse as the methods of surveilling blackness she discusses: from the design of the eighteenth-century slave ship Brooks, Jeremy Bentham's Panopticon, and The Book of Negroes, to contemporary art, literature, biometrics, and post-9/11 airport security practices. Surveillance, Browne asserts, is both a discursive and material practice that reifies boundaries, borders, and bodies around racial lines, so much so that the surveillance of blackness has long been, and continues to be, a social and political norm." <em>Summary taken from Duke University Press</em></p>
<p><a target="_blank" href="https://static1.squarespace.com/static/574dd51d62cd942085f12091/t/5d1cc2ff031e560001eccb24/1562166015547/Browne_Dark+Matters%2C+2015.pdf">Link to Free Preview</a> <a target="_blank" href="https://read-dukeupress-edu.proxy3.library.mcgill.ca/books/book/147/Dark-MattersOn-the-Surveillance-of-Blackness">No Full Free Text Available</a></p>
<p class="tags"><label>book</label><label>blackness</label><label>surveillance</label><label>technology</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Black Twitter: Building Connection Through Cultural Conversation</h1>
<h2>Meredith Clark</h2>
<h3>2015</h3>
</header>
<div class="content">
<p>Analyzing how Black Twitter creates "cultural conversation" on the internet through the hashtag #BlackTwitter to respond to news and cultural phenomenons in a way that connects individuals on a mass scale, whether it be large and serious topics or things that people find collectively entertaining or humorous.</p>
<p><a target="_blank" href="https://www.peterlang.com/view/9781454192015/chapter15.xhtml">Link to Text, No Free Text Available</a></p>
<p class="tags"><label>journal</label><label>article</label><label>black</label><label>twitter</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Beards, Sandals, and Other Signs of Rugged Individualism”: Masculine Culture within the Computing Professions</h1>
<h2>Nathan Ensmenger</h2>
<h3>2015</h3>
</header>
<div class="content">
<p>Explores the history of how men transformed the methodical and repetitive (thus feminine) field of computing into a profession with masculine identity which involved  artistic genius, personal eccentricity, antiauthoritarian behavior, and a characteristic “dislike of activities involving human interaction” aka rugged individualism.</p>
<p><a target="_blank" href="https://www.jstor.org/stable/10.1086/682955?seq=1#metadata_info_tab_contents">Link to full article</a></p>
<p class="tags"><label>Article</label><label>Silicon Valley</label><label>Masculine Culture</label><label>Computing</label><label>Gender</label><label>Industry</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Don't Hate the Player, Hate the Game: Internet Games, Social Inequality, and Racist Talk as Griefing</h1>
<h2>Lisa Nakamura</h2>
<h3>2015</h3>
</header>
<div class="content">
<p>Reading of a working essay recapping "the history of racist griefing online and link the current crisis in racial discourse in the US with this practice, exploring the implications for digital games as a public sphere," griefing being "the act of chronically causing consternation to other members of an online community, or more specifically, intentionally disrupting the immersion of another player in their gameplay."</p>
<p><a target="_blank" href="https://cyber.harvard.edu/events/luncheon/2010/06/nakamura">Link to Video Lecture</a></p>
</article>
<article>
<header class="heading">
<h1>Missing Data Sets and On Missing Datasets</h1>
<h2>Mimi Onuoha</h2>
<h3>2015-2018+ (Conference 2016)</h3>
</header>
<div class="content">
<p>"The Library of Missing Datasets is a physical repository of those things that have been excluded in a society where so much is collected." In this project, Onuoha gathers the data-sets which are missing, but should exist, in a society which prides itself so heavily on being saturated by data, in order to demonstrate how data isn't the answer to everything, the lack of certain datasets is a demonstration of greater power structures, and gathering those data-sets can also be strategy for resistence. It is important not to interpret the highlighting of missing datasets as a direct call or invocation to fill these gaps. Rather, the topic lends itself to specific and general considerations of our wider system of data collection.
If we begin from the understanding that there will always be data missing from any collection system, we allow ourselves the space to address resulting patterns of inclusion and exclusion.</p>
<p><a target="_blank" href="http://www.obfuscationworkshop.org/wp-content/uploads/2017/10/obfuscation-workshop-report.pdf#page=38">Link to Confrence Presentation Paper</a> <a target="_blank" href="https://mimionuoha.com/the-library-of-missing-datasets">Link to Project</a></p>
<p class="tags"><label>paper</label><label>project</label><label>missing</label><label>data</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Making Computers Accessible : Disability Rights and Digital Technology</h1>
<h2>Elizabeth R. Petrick</h2>
<h3>2015</h3>
</header>
<div class="content">
<p>"Petrick tells the compelling story of how computer engineers and corporations gradually became aware of the need to make computers accessible for all people. Motivated by user feedback and prompted by legislation [...], companies developed sophisticated computerized devices and software to bridge the accessibility gap. People with disabilities, Petrick argues, are paradigmatic computer users, demonstrating the personal computer’s potential to augment human abilities and provide for new forms of social, professional, and political participation." <em>Quoted from summary</em></p>
<p><a target="_blank" href="https://jhupbooks.press.jhu.edu/title/making-computers-accessible#:~:text=People%20with%20disabilities%2C%20Petrick%20argues,%2C%20professional%2C%20and%20political%20participation.">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Disability</label><label>Computing</label><label>Accessibility</label><label>Technology Studies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Innovating Inequity: If Race is a Technology, Postracialism is the Genius Bar</h1>
<h2>Ruha Benjamin</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>The author suggests that technology has created the new postracial in which racism is obscured by constant reinvention, the "universality" of technology, and that technology has innovated racism into its fabric while being "postracial" </p>
<p><a target="_blank" href="https://www.tandfonline.com/doi/abs/10.1080/01419870.2016.1202423">No Free Text Available</a></p>
<p class="tags"><label>journal</label><label>article</label><label>technology</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings</h1>
<h2>Tolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>This article shows how "word embeddings" a popular machine learning framework, exhibits female/male gender stereotypes and amplifies these biases, ie, associating the words receptionist and female.  The authors then offer their own methodology to remove these negative stereotypes by modifying the word embedding process and therefore not amplifying gender bias
 <a target="_blank" href="https://proceedings.neurips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html">Link to Free Text</a></p>
<p class="tags"><label>article</label><label>technology</label><label>bias</label><label>gender</label><label>stereotypes</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Black + Twitter: A Cultural Informatics Approach</h1>
<h2>Andre Brock Jr.</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>"Chris Sacca, activist investor, recently argued that Twitter IS Black Twitter. African American usage of the service often dominates user metrics in the United States, despite their minority demographic status among computer users. This talk unpacks Black Twitter use from two perspectives: analysis of the interface and associated practice alongside discourse analysis of Twitter’s utility and audience. Using examples of Black Twitter practice, I offer that Twitter’s feature set and ubiquity map closely onto Black discursive identity. Thus, Twitter’s outsized function as mechanism for cultural critique and political activism can be understood as the awakening of Black digital practice and an abridging of a digital divide."</p>
<p><a target="_blank" href="https://www.microsoft.com/en-us/research/video/black-twitter-a-cultural-informatics-approach/#!related_info">Link to Video Lecture</a></p>
<p class="tags"><label>videolecture</label><label>blacktwitter</label><label>activism</label><label>socialmedia</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Being a Scholar in the Digital Era: Transforming Scholarly Practice for the Public Good</h1>
<h2>Jessie Daniels and Polly Thistlewaite</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>This book looks "at scholarly practice in the digital era and consider how it can connect academics, journalists and activists in ways that foster transformation on issues of social justice" and "offers both a road map and a vision of what being a scholar can be when reimagined in the digital era to enliven the public good, as it discusses digital innovations in higher education as well as reflecting upon what these mean in an age of austerity."</p>
<p><a target="_blank" href="https://academicworks.cuny.edu/cgi/viewcontent.cgi?article=1516&amp;context=gc_pubs">Link to Free Text</a></p>
<p class="tags"><label>book</label><label>digital</label><label>academics</label><label>scholar</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Sci-Hub: A Solution to the Problem of Paywalls, or Merely a Diagnosis of a Broken System?</h1>
<h2>Jeremy S. Faust</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>This article looks at Sci-Hub, a website for pirated peer-review science and medicine research, and how its popularity is not necessarily due to the paywalls which prevent its users from accessing information, but the reliability and accessibility which it provides by having all these articles in one place without such a large "click burden" and "request access" barriers within researchers' own institutions.</p>
<p><a target="_blank" href="https://www.annemergmed.com/article/S0196-0644(16)30186-X/fulltext">Link to text</a></p>
<p class="tags"><label>article</label><label>accessibility</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Surveillance and the Public Sphere: confronting a democratic dilemma</h1>
<h2>Oscar H Gandy Jr and Professor Louise Amoore</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>"The increasingly precise segmentation and targeting of commercial messages has been enabled in large part through the analysis of massive amounts of transaction-generated-information. Although some attention has been paid to the use of these privacy invasive strategies within the public sphere, the use of personal data with regard to the formation, implementation and evaluation of public policies at the local, national and regional levels has largely been ignored. After discussing threats of political profiling to the future of public participation in the democratic process, Oscar Gandy will explore some possibilities for managing the nature, extent and distribution of these and associated societal harms." <em>Summary from video description</em></p>
<p><a target="_blank" href="https://www.lse.ac.uk/lse-player?id=3508">Link to Lecture Video</a></p>
<p class="tags"><label>lecture</label><label>video</label><label>surveillance</label><label>data</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Making Feminist Media: Third-Wave Magazines on the Cusp of the Digital Age</h1>
<h2>Elizabeth Groeneveld</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>Making Feminist Media looks at the history and the contemporary scene of feminist/radical publications and how they differ/compare, specifically the challenges which these publications face in an increasingly capitalistic economy which is directly related to a publication's ability to survive.</p>
<p><a target="_blank" href="https://muse.jhu.edu/book/49037">Link to Text</a></p>
<p class="tags"><label>article</label><label>feminism</label><label>capitalism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Feminist Bookstore Movement: Feminist Antiracism and Feminist Accountability</h1>
<h2>Kristen Hogan</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>"From the 1970s through the 1990s more than one hundred feminist bookstores built a transnational network that helped shape some of feminism's most complex conversations. Kristen Hogan traces the feminist bookstore movement's rise and eventual fall, restoring its radical work to public feminist memory. The bookwomen at the heart of this story—mostly lesbians and including women of color—measured their success not by profit, but by developing theories and practices of lesbian antiracism and feminist accountability. [...] In retelling their stories, Hogan not only shares the movement's tools with contemporary queer antiracist feminist activists and theorists, she gives us a vocabulary, strategy, and legacy for thinking through today's feminisms." <em>Quoted from publisher</em></p>
<p><a target="_blank" href="https://www.dukeupress.edu/the-feminist-bookstore-movement">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Feminism</label><label>Race</label><label>Communication technology</label><label>History</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Feminism, Labour and Digital Media: The Digital Housewife</h1>
<h2>Kylie Jarrett</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>"There is a contradiction at the heart of digital media. We use commercial platforms to express our identity, to build community and to engage politically. At the same time, our status updates, tweets, videos, photographs and music files are free content for these sites. We are also generating an almost endless supply of user data that can be mined, re-purposed and sold to advertisers. As users of the commercial web, we are socially and creatively engaged, but also labourers, exploited by the companies that provide our communication platforms. How do we reconcile these contradictions?</p>
<p>Feminism, Labour and Digital Media argues for using the work of Marxist feminist theorists about the role of domestic work in capitalism to explore these competing dynamics of consumer labour. It uses the concept of the Digital Housewife to outline the relationship between the work we do online and the unpaid sphere of social reproduction." <em>Summary taken from publisher site</em></p>
<p><a target="_blank" href="https://www.routledge.com/Feminism-Labour-and-Digital-Media-The-Digital-Housewife/Jarrett/p/book/9781138575660">Link to publisher's site, no free text available</a></p>
<p class="tags"><label>Book</label><label>New Media</label><label>Media Studies</label><label>Feminism</label><label>Marxism</label><label>Marxist Feminism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Black Data</h1>
<h2>Shaka McGlotten</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>Shaka McGlotten employs the notion of “black data” to explore how black queers trouble the invisible or taken-for-granted operations of states and corporations (mining the data of citizens). ...In particular, (McGlotten) applies a materialist black queer analytic to the “deep web” to grapple with the nsa surveillance scandal, new biometric technologies, and the tech-fueled gentrification of San Francisco. Drawing on case studies from everyday life and artistic practice, McGlotten links the deep web to the ways black bodies, and especially black queer bodies, are understood as data points, as statistical objects or deviations, rather than as ontologically material persons. Ultimately, the essay queries how black queers navigate the perils of data fields in online queer spaces where disclosing one’s racial identity can make one vulnerable to violence. <em>Chapter in "No Tea, No Shade: New Writings in Black Queer Studies" by Patrick E. Johnson</em></p>
<p><a target="_blank" href="https://transreads.org/wp-content/uploads/2019/07/2019-07-12_5d2916e6597b6_Literariness.org-E.-Patrick-Johnson-ed.-No-Tea-No-Shade_-New-Writings-in-Black-Queer-Studies-Duke-University-Press-2016-compressed.pdf">Link to Free Text</a></p>
</article>
<article>
<header class="heading">
<h1>The Social Life of DNA: Race, Reparations, and Reconciliation After the Genome</h1>
<h2>Alondra Nelson</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>"Social commentary and critique of DNA genome testing, particularly for African American people. "DNA-based techniques are being used in myriad ways, including grappling with the unfinished business of slavery: to foster reconciliation, to establish ties with African ancestral homelands, to rethink and sometimes alter citizenship, and to make legal claims for slavery reparations specifically based on ancestry." <em>Summary from Penguin Random House</em></p>
<p><a target="_blank" href="https://www.penguinrandomhouse.com/books/250539/the-social-life-of-dna-by-alondra-nelson/">Link to Text, No Free Text Available</a></p>
<p class="tags"><label>book</label><label>science</label><label>dna</label><label>medicine</label><label>race</label><label>slavery</label><label>reperations</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Intersectional Internet: Race, Sex, Class, and Culture Online</h1>
<h2>Safiya Umoja Noble and Brendesha M. Tynes (eds)</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>Collection of internet studies pieces analyzing how hardware, code, software and internet infrastructure can be implicated in preexisting uneven power relations. Urges for more research on the impacts of these relations in the context of the internet from an intersectional approach.</p>
<p><a target="_blank" href="https://www.peterlang.com/view/title/22893">Link to Text</a></p>
<p class="tags"><label>book</label><label>intersectionalism</label><label>power</label><label>internet</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Weapons of Math Destruction: How big data increases inequality and threatens democracy</h1>
<h2>Cathy O'Neil</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>Analyzes how algorithms and big data govern our lives in micro to macro ways and are supposed to increase fairness, but mathematical models often reinforce inequalities and discrimination, "The Dark Side to Big Data."</p>
<p><a target="_blank" href="http://governance40.com/wp-content/uploads/2019/03/Weapons-of-Math-Destruction-Cathy-ONeil.pdf">Link to Free Text</a></p>
<p class="tags"><label>book</label><label>bigdata</label><label>data</label><label>algorithms</label><label>inequality</label><label>discrimination</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>On the Cruelty of Really Writing a History of Machine Learning</h1>
<h2>Aaron Plasek</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>This article discusses historical perceptions of machine learning. It argues that machine learning is often presented as existing in the future, and current uses of machine learning—and the biases they reproduce—are often overlooked.</p>
<p><a target="_blank" href="https://ieeexplore.ieee.org/document/7763733">Link to full article</a></p>
<p class="tags"><label>Article</label><label>Machine Learning</label><label>History</label><label>AI</label><label>Artificial Intelligence</label><label>Datasets</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Rise of the Machines : A Cybernetic History</h1>
<h2>Thomas Rid</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>Historicizing cybernetics from its birth to current day, Rid shows how Cybernetics (the science of communications and automatic control systems in both machines and living things) born in the Post-War era, was never a Post-War science, but rather was focused on how to enforce Cold War theatres of dominance and war. Thus, despite the utopianist imagination born out of cybernetics (ie. cyborg manifesto), the history of the science reveals how from the start to the present, it was focused on national security, surveillance and American militarism.</p>
<p><a target="_blank" href="https://wwnorton.com/books/Rise-of-the-Machines/">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Cybernetics</label><label>History</label><label>Computing</label><label>Surveillance</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Hail the Maintainers</h1>
<h2>Andrew Russell</h2>
<h3>2016</h3>
</header>
<div class="content">
<p>A historically mindful article critiquing the rhetoric of innovation, and upholding the importance of the unglamorous labour of technology maintenance.  For Russel, since post-WW2, "innovation" has become a buzzword that originally stemmed from the replacement of the word progress as a less political, less ethically bound version of technoutopianism.  From there, we see that innovation rhetoric, creating new bigger systems to drastically overhaul the status quo, is pervasive and yet, not realistically bound as the majority of the technologies we use as humans hold up and need to be maintained.  Thus, rather than looking toward the 1% of "innovators," we should centre the large numbers of "maintainers" who ensure that our current infrastructure continue to run.</p>
<p><a target="_blank" href="https://aeon.co/essays/innovation-is-overvalued-maintenance-often-matters-more">Link to Text</a></p>
<p class="tags"><label>article</label><label>technology</label><label>maintenance</label><label>innovation</label><label>book</label><label>chapter</label><label>data</label><label>black</label><label>queer</label><label>technology</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Building Capacity for  Digital Humanities: A Framework for Institutional Planning</h1>
<h2>Kirk Anne, Tara Carlisle, Quinn Dombrowski, Erin Glass, Tassie Gniady, Jason Jones, Joan Lippincott, John MacDermott, Megan Meredith-Lobay, Barbara Rockenbach, Annelie Rugg, Ashley Sanders, John Simpson, Bryan Sinclair, and Justin Sipher</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>A working paper outlining the steps that intstitutions should take in order to allow scholars to do research in the digital humanities since the use of technology is more new to humanities but not so much to say, STEM research. Outlines a practical framework "for capacity building to develop institutional DH support for IT staff, librarians, administrators and faculty" in three stages.</p>
<p><a target="_blank" href="https://slidelegend.com/building-capacity-for-digital-humanities-a-educause-library_59bf8fe91723dd12421660b3.html">Link to Free Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>technology</label><label>digital</label><label>humanities</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Gender Binary Will Not Be Deprogrammed: Ten Years of Coding Gender on Facebook</h1>
<h2>Rena Bivens</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>This article dives into the deeply engrained gender binary in Facebooks coding towards advertizers and in its own inception, despite Facebooks new roll out of 58 different gender options in 2014.  The article "exposes Facebook's focus on authenticity as an insincere yet highly marketable regulatory regime."</p>
<p><a target="_blank" href="http://humanrightsindigitalage.pbworks.com/w/file/fetch/94878209/SSRN-id2431443.pdf">Link to Free Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>gender</label><label>binary</label><label>facebook</label><label>coding</label><label>algorithm</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Gender Shades: Intersectional Phenotypic and Demographic Evaluation of Face Datasets and Gender Classifiers</h1>
<h2>Joy Buolamwini</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>Masters thesis analyzing datasets that look into AI based facial recognition technologies which profile/identify people in the contexts of hiring, police confrontations, self driving cars and surveillance etc.  Concludes that the datasets that these facial recognition technologies are learning from are overwhelmingly light-skinned, and often also overwhelmingly male.  This greatly effects these technologies' accuracy and margin of error in identifying darkskinned women and men, which could have many negative effects.</p>
<p><a target="_blank" href="https://dam-prod.media.mit.edu/x/2018/02/05/buolamwini-ms-17_WtMjoGY.pdf">Link to Masters thesis</a></p>
<p class="tags"><label>Dissertation</label><label>Masters Thesis</label><label>AI</label><label>Artificial Intelligence</label><label>Data Sets</label><label>Racial Profiling</label><label>Race</label><label>Coded Bias</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Network Sovereignty: Building the Internet across Indian Country</h1>
<h2>Marisa Elena Duarte</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>"In 2012, the [UN] General Assembly determined that affordable Internet access is a human right, critical to citizen participation in democratic governments. Given the significance of information and communication technologies (ICTs) to social and political life, many U.S. tribes and Native organizations have created their own projects, from streaming radio to building networks to telecommunications advocacy. [This book] examines these ICT projects to explore the significance of information flows and information systems to Native sovereignty, and toward self-governance, self-determination, and decolonization. By reframing how tribes and Native organizations harness these technologies as a means to overcome colonial disconnections, Network Sovereignty shifts the discussion of information and communication technologies in Native communities from one of exploitation to one of Indigenous possibility." <em>Summary quoted from publisher</em></p>
<p><a target="_blank" href="https://uwapress.uw.edu/book/9780295741826/network-sovereignty/">Link to publisher site, no free text available</a></p>
<p class="tags"><label>Book</label><label>Indigenous Sovereignty</label><label>Information</label><label>Communication</label><label>Technology</label><label>Media Studies</label><label>Indigenous Studies</label><label>Decolonization</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Long-Term Trends in the Public Perception of Artificial Intelligence</h1>
<h2>Ethan Fast and Ethan Horowitz</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>This paper is about the evolution of perceptions of AI in the last 30 years based on discussions of AI in the New York Times.  It observes that discussion of AI increased sharply 2009 onwards, and perceptions have been larely optimistic (particularly in healthcare and education), however the potential loss of control, ethical problems and negative effects of AI have also incresased.</p>
<p><a target="_blank" href="https://arxiv.org/pdf/1609.04904.pdf">Link to full article</a></p>
<p class="tags"><label>Article</label><label>Conference Proceedings</label><label>AI</label><label>Artificial Intelligence</label><label>Ethics</label><label>Healthcare</label><label>Education</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Examining Black Feminism in the Digital Era</h1>
<h2>Kishonna L. Gray</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>"It is important to examine the digital manifestations of misogynoir – or what it means to be a Woman of Color existing in the hegemonic spaces of digital technology. But our conceptual frameworks fail to capture the everyday practices that Women of Color exhibit online. In this talk Kishonna L. Gray [...] discusses the frameworks of Black Digital Feminism, useful to not only examine how structures influence practices, but also tools that have been implemented to resist such hegemony."
<em>Summary from Video Description</em></p>
<p><a target="_blank" href="https://www.youtube.com/watch?v=7fYeL3WH4Xk">Link to Video Lecture</a></p>
<p class="tags"><label>videolecture</label><label>blackfeminism</label><label>digital</label><label>technology</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>How #Blacklivesmatter: exploring the role of hip-hop celebrities in constructing racial identity on Black Twitter</h1>
<h2>Summer Harlow and Anna Benbrook</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>The authors of this article qualitatively and quantitatively studied #BlackLivesMatter on Twitter in terms of Black hip-hop celebrities and how these people constructed black identity around the BLM movement, since Black Twitter, and hip-hop's influence in American culture/counterculture is so immense.  They concluded that despite the hashtag being closely associated with the protests in Ferguson and activism at large, Black hip-hop celebrities were a) less inclined to tweet with the hashtag than white celebs and b) fell into four distinct themes: speaking to whites, solidarity, Black is beautiful, and equality, which shows how they desire to construct black identity.</p>
<p><a target="_blank" href="https://www.tandfonline.com/doi/pdf/10.1080/1369118X.2017.1386705?casa_token=BBhENKNjUTEAAAAA:DYaKCkO0UgnqZW3rQE8Kv5YiVOiBwhlh3OUO2JNOdc3NQ6BtjkslQ-IPJHzdiJzlQx1vehPqysc">Link to open access article</a></p>
<p class="tags"><label>article</label><label>Activism</label><label>Police Brutality</label><label>Race</label><label>Social Identity</label><label>Twitter</label><label>Social Media</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Programmed Inequality : How Britain Discarded Women Technologists and Lost Its Edge in Computing</h1>
<h2>Mar Hicks</h2>
<h3>2017</h3>
</header>
<div class="content">
<p><em>Programmed Inequality</em> is about the history of computing. It discusses how from World War II to the 1960's, Britain was at the cutting edge of computer technology but lost that edge, in large part due to the way that the largely female, technologically oriented workforce was structurally replaced by men because of discrimination and the assumption that computer science should be male-dominated naturally.  These decisions caused "the civil service and sprawling public sector'to make decisions that were disastrous for the British computer industry and the nation as a whole."  A lesson in how even women who possess the skills of computing will not naturally fit into the industry, and how the US risks repeating those risks in the 21st century.</p>
<p><a target="_blank" href="https://mitpress.mit.edu/books/programmed-inequality">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Computing</label><label>Gender</label><label>History</label><label>Britain</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>"Whoops I am a Lady on the Internet”: Digital Feminist Counter-Publics</h1>
<h2>Marcelle Kosman, Hannah McGregor, Clare Mulcahy</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>Intro to a collection of essays that show what it means to be a lady on the internet, including being faced with personal threats or threatening groups of people, and how women navigate their fraught relationship with the internet.</p>
<p><a target="_blank" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwi1_6SFtvPpAhVhneAKHTRQC78QFjABegQIARAB&amp;url=https%3A%2F%2Fjournals.msvu.ca%2Findex.php%2Fatlantis%2Farticle%2Fdownload%2F5409%2F134-136%2520PDF%2F&amp;usg=AOvVaw2LXZmdsOvjHlKR0q3IZ3ue&amp;cshid=1591660712550433">Link to Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>gender</label><label>internet</label><label>onlineharassment</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Predatory Data: Gender Bias in Artificial Intelligence</h1>
<h2>Vidisha Mishra and Madhulika Srikumar</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>"As patriarchy and prejudice become encoded in machines, fighting (gender) bias in data and deployment through increasing diversity in AI research will become important. As machine learning permeates every aspect of people’s lives, AI is no longer a mere object of science fiction." <em>Quoted from article conclusion</em></p>
<p><a target="_blank" href="https://www.orfonline.org/wp-content/uploads/2017/10/CyFy_2017_Journal.pdf">Link to journal article</a></p>
<p class="tags"><label>Article</label><label>AI</label><label>Artificial Intelligence</label><label>Gender Bias</label><label>Diversity</label><label>Gender</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Montreal Declaration for a Responsible Development of Artificial Intelligence</h1>
<h2>Montreal Institute for Leaning Algorithms (MILA)</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>The declaration "will help guide the development of artificial intelligence toward morally and socially desirable ends" and help cultivate trust toward artificially intelligent systems. Promotes principles of well-being of all sentient beings, respecting people's autonomy, protecting privacy, maintain bonds of solidarity, be developped democratically, strive for equitable and diverse society, and be developped with caution, responsability and sustainability.</p>
<p><a target="_blank" href="https://www.montrealdeclaration-responsibleai.com/the-declaration">Link to declaration</a></p>
<p class="tags"><label>Article</label><label>Declaration</label><label>Artificial Intelligence</label><label>Algorithms</label><label>Sustainable Development</label><label>Ethics</label><label>AI</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Resource Scarcity and Socially Just Internet Access over Time and Space</h1>
<h2>Daniel Pargman and Bjorn Wallsten</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>"the infrastructure for computing is dependent on limited non-renewable material resources and ... the costs for extraction can be expected to rise during the coming decades due to limits on mining the Earth’s crust. The current path of innovating and deploying progressively more advanced systems for computing is hardly sustainable in the medium to long run. Bearing this in mind, it would be prudent to husband resources and to shift from an emphasis on innovation to a focus on maintenance. The goal should be to reject “the cornucopian paradigm” [44] and aim for developing a suitable infrastructure and a “sufficient” level of service so as to guarantee the largest functionality for the lowest cost and the greatest number of people for the longest possible duration both within and between countries. This is what we mean when we refer to socially just internet access over time (extending the benefits of digital technologies as far as possible into the future) and space (extending the benefits of digital technologies to the largest number of people possible). To that end, it seems prudent to restrict innovations that use up scarce resources, and especially so if they deliver only marginal improvements that benefit only the few. We have refrained from suggesting exactly how this could be done, but any concrete policy suggestion for how to alter incentives for innovation is bound to be provocative-bordering-on-incendiary. </p>
<p><a target="_blank" href="https://colet.space/wp-content/uploads/2017/12/limits17-pargman.pdf">Link to full open access article</a></p>
<p class="tags"><label>Article</label><label>Sustainability</label><label>Infrastructure</label><label>Maintenance</label><label>Copper</label><label>Innovation</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Twitter and Tear Gas: The Power and Fragility of Networked Protest</h1>
<h2>Zeynep Tufekci</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>"Could the ability to organize massive protests quickly on Facebook and Twitter be making those protests vulnerable in the long term? If new technologies are so empowering, why are so many movements failing to curb authoritarianism’s rise? Is a glut of misinformation more effective censorship than directly forbidding speech? Why are so many of today’s movements leaderless? Zeynep Tufekci answers these questions and more," explaining the role the internet played in movmeents such as the Zapatista uprisings, the Arab Spring, the Occupy Movement and in Gezi Park (Turkey.) "She also looks at how governments have responded to the rise of digital tools with their own methods, including misinformation, distraction, and surveillance." Offers essential and surprising insights into the public sphere and future of governance in the 21st century.</p>
<p><a target="_blank" href="twitterandteargas.com">Link to the book's website</a></p>
<p class="tags"><label>Book</label><label>Social Media</label><label>Activism</label><label>Surveillance</label><label>Political uprising</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Technically Wrong: Sexist Apps, Biased Algorithms, and Other Threats of Toxic Tech</h1>
<h2>Sara Wachter-Boettcher</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>"Buying groceries, tracking our health, finding a date: whatever we want to do, odds are that we can now do it online. But few of us realize just how many oversights, biases, and downright ethical nightmares are baked inside the tech products we use every day. It’s time we change that.In <em>Technically Wrong</em>, Sara Wachter-Boettcher demystifies the tech industry, leaving those of us on the other side of the screen better prepared to make informed choices about the services we use—and to demand more from the companies behind them." <em>Summary by Norton Press</em></p>
<p><a target="_blank" href="https://wwnorton.com/books/Technically-Wrong/">Link to Text, No Free Text Available</a></p>
<p class="tags"><label>book</label><label>algorithms</label><label>technology</label><label>apps</label><label>biases</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Blockchain Just Isn't As Radical As You Want It To Be</h1>
<h2>Rachel O'Dwyer</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>Interrogates the technological utopianist rhetoric surrounding blockchain technology - a peer-to-peer, "trustless" ledger system which relies on the transparency and cooperation of all participants in a network, such as bitcoin - ASSUMPTION #1: WE CAN REPLACE MESSY AND TIME-CONSUMING SOCIAL PROCESSES WITH ELEGANT TECHNICAL SOLUTIONS. ASSUMPTION #2: THE TECHNICAL CAN INSTANTIATE NEW SOCIAL OR POLITICAL PROCESSES. the author complicates these assumptions by saying "We need to find ways to embrace not only technical solutions, but also people who have experience in community organizing and methods that foster trust, negotiate hierarchies, and embrace difference"</p>
<p><a target="_blank" href="https://longreads.com/2018/02/15/blockchain-just-isnt-as-radical-as-you-want-it-to-be/">Link to Text</a></p>
<p class="tags"><label>article</label><label>techbology</label><label>bitcoin</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>How We Became Machine Readable</h1>
<h2>Mimi Onuoha</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>In this talk, Mimi Onuoha discusses how data sets should be intrinsically tied to the data collection process, and how data that claims to represent a whole set of people or things often systematically exclude outliers or variants. Namely, Onuoha discusses the Middletown, Muncie ID case where two researchers collected large swathes of social data to represent the "average american town" and thus america as a whole, while excluding immigrants and african americans in the study.  She also discusses her catcaller experiment, her study wth Fulbright-Nat Geo where she tracked the location data of four groups of participants intimately to tell stories, and the missing datasets project, focusing on the data collection process.</p>
<p><a target="_blank" href="https://vimeo.com/233011125">Link to Video</a></p>
<p class="tags"><label>video</label><label>lecture</label><label>missing</label><label>data</label><label>machine</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>How We Get Free</h1>
<h2>KY Taylor</h2>
<h3>2017</h3>
</header>
<div class="content">
<p>KY Taylor interviews three founding members of the Combahee River Collective— Beverly Smith, Barbara Smith and Demita Frazier— on the 40th anniversary of their statement.  Covers things like the anti-war movement, students for a democratic society (sds), and leftist politics from black feminist Marxist perspective</p>
<p><a target="_blank" href="https://static1.squarespace.com/static/5ad0d247af209613040b9ceb/t/5db1bd26da7aed20882b835b/1571929383843/Taylor+%28ed.%29+2017-+How+We+Get+Free-CRC+Manifesto+and+B+Smith+%5Bexcerpt%5D.pdf">Link to Free Text</a></p>
<p class="tags"><label>book</label><label>black</label><label>feminism</label><label>history</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Pattern Discrimination: In Search of Media</h1>
<h2>Clemens Apprich, Wendy Hui Kyong Chun,  Florian Cramer, and Hito Steyerl</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>"The articles collected in this volume do not deny that Big Data,  machine learning, and network analytics constitute a new authority— after the divine and the rational. But they do plead for a certain serenity, for a strategic step back to not get caught in the narcissistic admiration of our own image. Because this is what digital cultures ultimately are: the reflection of our own lives— messy, beautiful, and unjust." <em>Summary taken from introduction</em></p>
<p><a target="_blank" href="https://meson.press/wp-content/uploads/2018/11/9783957961457-Pattern-Discrimination.pdf">Link to Free Text</a></p>
<p class="tags"><label>book</label><label>data</label><label>discrimation</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Engineered for Dystopia</h1>
<h2>David A Banks</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>This article traces the connections of the engineering profession historically and presently with authoritarianism, fascism and fundamentalism.  They're desire for a well ordered world, centralized power to create big state structures, and the lack of ethics regulation leaving much up to corporate interest, are all problematic to Banks, and they suggest cultivating the engineering mindset of building things as a form of care, considering other liberal arts and philosophies, and interogating the power structures that engingeering is implicated in.</p>
<p><a target="_blank" href="https://thebaffler.com/latest/engineered-for-dystopia-banks">Link to Text</a></p>
<p class="tags"><label>article</label><label>engineering</label><label>design</label><label>ethics</label><label>facism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classiﬁcation</h1>
<h2>Joy Buolamwini and Timnit Gebru</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>Analayzes datasets to evaluate bias in automated facial analysis algorithms in relation to phenotypes such as light skin and dark skin, which reveal that dark skinned females are the most misclassified group with a large disparity between them and light skinned males and everything in between.</p>
<p><a target="_blank" href="proceedings.mlr.press/v81/buolamwini18a.html">Link to article</a></p>
<p class="tags"><label>Conference Paper</label><label>Article</label><label>AI</label><label>Artifiical Intelligence</label><label>Coded Bias</label><label>Data Sets</label><label>Racial Profiling</label><label>Race</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Artificial Unintelligence: How computers misunderstand the world</h1>
<h2>Meredith Broussard</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>In this book, Meredith Broussard argues that our collective desire to do everything digitally has resulted in poorly designed systems, and that there are fundamental limits to what we can (and should) do with technology.  She argues against technochauvinism - social problems will continue to exist in the technologically driven utopia, and "the cyborg future is not coming any time soon"  If we understand technologies limits, we can make better choices of what we should do with it.</p>
<p><a target="_blank" href="https://mitpress.mit.edu/books/artificial-unintelligence">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Artificial Intelligence</label><label>Technochauvinism</label><label>Technology</label><label>Computers</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Design Justice, AI, and Escape from the Matrix of Domination</h1>
<h2>Sasha Costanza-Chock</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>Through the author's personal experience interacting with A.I. technologies as a trans non-binary femme presenting person, this article argues that people's experience with AI systems differ, and they should be redesigned.  However, even though A.I. development is primarily driven by capitalist profitability, and that there is a growing community of technologists, computer scientists etc. who are taking these issues into account.</p>
<p><a target="_blank" href="https://jods.mitpress.mit.edu/pub/costanza-chock/release/4">Link to open access article</a></p>
<p class="tags"><label>Article</label><label>Artificial Intelligence</label><label>Queer</label><label>Technology</label><label>Design Justice</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>I Was Trolled. I’m Turning it into a Teaching Opportunity</h1>
<h2>Emily Contois</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>A feminist professor's experience with online trolls re: a critique she had on hot ones, the web-based show, and how she turned that experience into a part of her fall curriculum</p>
<p><a target="_blank" href="https://nursingclio.org/2018/07/17/i-was-trolled-heres-why-im-turning-it-into-a-teaching-opportunity/">Link to Text</a></p>
<p class="tags"><label>article</label><label>online</label><label>trolling</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>What the Internet is for</h1>
<h2>Cory Doctorow</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>Doctorow insists that while the internet is built on revolutionary technologies such as end-to-end communications and universal computers, it is not in itself revolutionary.  In fact, the internet has aided and abetted authoritarian regimes and suppressed revolutionaries in some cases.  However, he argues that although the internet is not inherently revolutionary, it has the potential to be used for revolutionary purposes, such as coordinating mass movements against authority.  Thus, it is not enough to say the internet itself is revolutionary technology.</p>
<p><a target="_blank" href="https://locusmag.com/2018/11/cory-doctorow-what-the-internet-is-for/">Link to full article</a></p>
<p class="tags"><label>Activism</label><label>Article</label><label>Internet</label><label>Politics</label><label>Revolutionary Technology</label><label>Protest</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor</h1>
<h2>Virginia Eubanks</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>In Automating Inequality, Virginia Eubanks systematically investigates the impacts of data mining, policy algorithms, and predictive risk models on poor and working-class people in America. Specifically, how automated systems and new technologies are used to contain, investigate and punish those with the least power</p>
<p><a target="_blank" href="https://school.hbh7.com/pdfs/RPI/Automating%20Inequality%20-%20Virginia%20Eubanks.pdf">Link to Free Text</a></p>
<p class="tags"><label>book</label><label>technology</label><label>inequality</label><label>poverty</label><label>data</label><label>algorithms</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>I get by with a little help from my friends: The Ecological Model and Support for Women Scholars Experiencing Online Harassment</h1>
<h2>Chandell Gosse, Jaigris Hodson, Shandell Houlden, George Veletsianos</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>This article aims to understand the phenomenon behind online abuse and harassment towards women scholar. Data was collected from 14 interviews to determine and report on the types of supports these women sought during and after their experiences. There are three levels of support: personal and social; organizational, technological, and sectoral; larger cultural and social attitudes and discourses. Participants relied on social and peronal support most frequently, but they often relied on multiple supports across all three levels. The authors used an ecological model to demonstrate how different types of support are interconnected.</p>
<p><a target="_blank" href="https://journals.uic.edu/ojs/index.php/fm/article/view/9136/0">Link to Text</a></p>
<p class="tags"><label>article</label><label>onlineharassment</label><label>internet</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Racial Justice Activist Hashtags: Counterpublics and Discourse Circulation</h1>
<h2>Rachel Kuo</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>Kuo analyzes how hashtags such as #NotYourAsianSideKick and #SolidarityforWhiteWomen create discourse within and outside of twitter, and are fluid forms of discourse which intersect different publics and widely circulate in a way which create new discourse.</p>
<p><a target="_blank" href="https://journals-sagepub-com.proxy3.library.mcgill.ca/doi/10.1177/1461444816663485">Link to Text</a></p>
<p class="tags"><label>article</label><label>intersectionalism</label><label>feminism</label><label>race</label><label>gender</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Broad Band : The Untold Story of the Women Who Made the Internet</h1>
<h2>Claire Lisa Evans</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>The historical biographies of women who played a big role in the development of technology and internet, including Ada Lovelace, Grace Hopper, Elizabeth (Jake) Feinler and Stacy Horn. "In a world where tech companies are still male-dominated and women are often dissuaded from STEM careers, Broad Band shines a much-needed light on the bright minds history forgot, from pioneering database poets, data wranglers, and hypertext dreamers to glass ceiling-shattering dot com-era entrepreneurs."</p>
<p class="tags"><label>Book</label><label>English</label><label>feminism</label><label>women</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Becoming NULL: Queer Relations in the Excluded Middle</h1>
<h2>Jacob Gaboury</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>Article discusses Facebook's move to include 56 gender identities (from 2) as not queer acceptence, but as a part of a society of control and identification which strives to know more about people using Facebook plainly, to collect that data for advertisements.  Demonstrably, trans people and drag performers were removed from Facebook and flagged, told that they had to provide legal documentation of their name to keep those profiles.  Thus, facebook really doesn't care about respecting gender identities and inclusivity.</p>
<p><a target="_blank" href="https://www.womenandperformance.org/bonus-articles-1/jacob-gaboury-28-2/">Link to full article</a></p>
<p class="tags"><label>article</label><label>Big Data</label><label>Queer subjects</label><label>Social Media</label><label>Facebook</label><label>Gender</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Woke Gaming: Digital Challenges to Oppression and Social Injustice</h1>
<h2>Kishonna L. Gray and David J. Leonard (eds.)</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>"Woke Gaming examines resistance to problematic spaces of violence, discrimination, and microaggressions in gaming culture. The contributors of these essays seek to identify strategies to detox gaming culture and orient players and gamers toward progressive ends. From Anna Anthropy’s Keep Me Occupied to Momo Pixel’s Hair Nah, video games can reveal the power and potential for marginalized communities to resist, and otherwise challenge dehumanizing representations inside and outside of game spaces." <em>Summary taken from University of Washingston Press</em></p>
<p><a target="_blank" href="https://www.perlego.com/book/834171/woke-gaming-digital-challenges-to-oppression-and-social-injustice-pdf">Link to Free Text with Free Trial to Perlego</a></p>
<p class="tags"><label>book</label><label>gaming</label><label>discrimination</label><label>resistance</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Gender Recognition or Gender Reductionism?: The Social Implications of Embedded Gender Recognition Systems</h1>
<h2>F. Hamidi, M.K. Scheuerman and S.M Branham</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>Researchers interviewed 13 transgender individuals about their thoughts on Automated Gender Recognition (AGR), ie. using a variety of visual and audible factors to determine ones gender.  They concluded that AGR systems and their embedded uses in society such as security or marketing are harmful and dissaproved/disbelieved by transgender people -- who represent those most marginalized by gender essentialism in society.</p>
<p><a target="_blank" href="https://dl.acm.org/doi/10.1145/3173574.3173582">Link to article</a></p>
<p class="tags"><label>Article</label><label>Automated Gender Recognition</label><label>AGR</label><label>Gender idendity</label><label>Transgender</label><label>Autonomy</label><label>User-centred design</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Elites like Amazon’s Jeff Bezos think they’re being philanthropic. But they could do so much more.</h1>
<h2>Eric Johnson</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>Johnson explains how very rich "philanthropists" often dedicate money to and pledge their support for causes that they often are guilty of contributing negatively towards - such as global inequalities and climate change, but will never do anything that harms their bottom line - hence the reason why this philanthropy is a charade of the elites. His new book "the elite charade of changing the world" argues that we've normalized and bought into the idea that the rich and powerful have our best interest in mind, when in fact they are interested in preserving the unequal status quo from which they benefit.</p>
<p><a target="_blank" href="https://www.vox.com/2018/10/3/17930990/anand-giridharadas-winners-take-all-book-changing-world-kara-swisher-decode-podcast-jeff-bezos">Link to Text</a></p>
<p class="tags"><label>article</label><label>amazon</label><label>inequality</label><label>oppresion</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Gender Bias in Artificial Intelligence: The Need for Diversity and Gender Theory in Machine Learning</h1>
<h2>Susan Leavy</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>Analyzes how gender-biases can become embedded in AI through machine learning if datasets are embedded with the same gender-bias which the data that it is fed may contain. For example, the naming of humans as "mankind" or the idea of the "family man" with no female equivalent, the ordering of "man" before "wife", "boy" before "girl", or the sheer lack of women present in certain literature to name a few.  Since AI developpers are overwhelmingly male, and those who call-out and see gender-bias in machine learning are women themselves, women ought be called in to intervene and point out these potentialities.</p>
<p><a target="_blank" href="https://ieeexplore.ieee.org/document/8452744">Link to article</a></p>
<p class="tags"><label>Article</label><label>AI</label><label>Artificial Intelligence</label><label>Diversity</label><label>Gender</label><label>Gender Theory</label><label>Gender Bias</label><label>Data</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Making Kin with Machines</h1>
<h2>Jason Edward Lewis, Archer Pechawis, and Suzanne Kite</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>This essay details the possibilities of using indigenous kinship systems to make kin with the technology we are in relationship with. Specifcally, how we can use indigenous understandings of kinship to move ethically with AI and other technologies. </p>
<p><a target="_blank" href="https://jods.mitpress.mit.edu/pub/lewis-arista-pechawis-kite/release/1">Link to Free Text</a></p>
<p class="tags"><label>essay</label><label>kin</label><label>indigenous</label><label>machine</label><label>AI</label><label>technology</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Girls Who Coded: Gender in Twentieth Century U.K. and U.S. Computing</h1>
<h2>Kate M. Milner</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>This is a review of three books detailing womens involvement in 20th century computer and code development, women's inequal roles in the tech industry now and how to address the problem. Essentially three book reviews in one for the following: Programed Inequality by M. Hicks, Recoding Gender by J. Abbate, and The Computer Boys Take Over by N.L. Ensmenger.</p>
<p><a target="_blank" href="https://www.academia.edu/38702764/Girls_Who_Coded_Gender_in_Twentieth_Century_U.K._and_U.S._Computing">Link to Text</a></p>
<p class="tags"><label>review</label><label>essay</label><label>gender</label><label>girlswhocode</label><label>womenintech</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Algorithms of Oppression: How Search Engines Reinforce Racism</h1>
<h2>Safiya Umoja Noble</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>"Safiya Umoja Noble challenges the idea that search engines like Google offer an equal playing field for all forms of ideas, identities, and activities. Data discrimination is a real social problem. Noble argues that the combination of private interests in promoting certain sites, along with the monopoly status of a relatively small number of Internet search engines, leads to a biased set of search algorithms that privilege whiteness and discriminate against people of color, especially women of color."</p>
<p><a target="_blank" href="https://www-degruyter-com.proxy3.library.mcgill.ca/document/doi/10.18574/9781479833641/html">Link to Text</a></p>
<p class="tags"><label>book</label><label>data</label><label>discrimination</label><label>race</label><label>gender</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>A People's Guide to AI</h1>
<h2>Mimi Onuoha</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>A comprehensive begginer's guide to AI and data-driven tech. Mission of the book is to open up conversation around AI by demystifying, situating and shifting the narrative about what types of use cases AI can have for everday people. "Resists narratives of dystopian futures by using popular education, design and storytelling to lay the groundwork for creative imaginings.</p>
<p><a target="_blank" href="https://www.alliedmedia.org/files/peoples-guide-ai.pdf">Link to free zine</a></p>
<p class="tags"><label>Zine</label><label>AI</label><label>Artificial Intelligence</label><label>Popular Education</label><label>Digital Divide</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>A People’s Guide To AI: A Beginner's Guide to Understanding AI</h1>
<h2>Mimi Onuoha and Diana Nucera a.k.a. Mother Cyborg, with design and illustration by And Also Too.</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>The People’s Guide to Artificial Intelligence is an educational and speculative approach to understanding artificial intelligence (AI) and its growing impact on society. The 78-page booklet explores the forms AI takes today and the role AI-based technologies can play in fostering equitable futures. The project resists narratives of dystopian futures by using popular education, design, and storytelling to lay the groundwork for creative imaginings. Written by Mimi Onuoha and Diana Nucera a.k.a. Mother Cyborg, with design and illustration by And Also Too.</p>
<p><a target="_blank" href="https://alliedmedia.org/speaker-projects/a-peoples-press">Link to digital copy of zine</a></p>
<p class="tags"><label>Zine</label><label>AI</label><label>Artificial intelligence</label><label>Popular Education</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Digital Defense Playbook/ Cuaderno De Juegos De Defensa Digital</h1>
<h2>Our Data Bodies</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>"Our Data Bodies (ODB) has conducted research and produced a workbook of popular education activities focused on data, surveillance, and community safety to co-create and share knowledge, analyses, and tools for data justice and data access for equity. We hope that this project will be helpful to movements for justice grounded in peoples’ realities. We hope that our work will enhance trusted models of community health and safety and help illuminate the differences between being safe and being secure. We wish this Digital Defense Playbook, with all its activities, tools, tip sheets, and reflection pieces, will support organizations and community members involved in intersectional fights for racial justice, LGBTQ liberation, feminism, immigrant rights, economic justice, and other freedom struggles, to help us understand and address the impact of data-based technologies on our social justice work. This work is critical, because our data are our stories. When our data are manipulated, distorted, stolen, exploited, or misused, our communities are stifled, obstructed, or repressed, and our ability to self-determine and prosper is systematically controlled."<em>Quoted from page 5</em></p>
<p><a target="_blank" href="https://www.odbproject.org/tools/">Link to project site</a></p>
<p class="tags"><label>Zine</label><label>Big Data</label><label>Gender</label><label>Feminism</label><label>Race</label><label>Data Justice</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Diversity is a Dangerous Set-up</h1>
<h2>Chanda Prescod-Weinstein</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>"Trying to use science to analyze and fix racism is a dangerous proposition. The science behind implicit bias may be bunk. Promoting diversity rather than substantive structural change will not create equal opportunity and equal outcomes. A focus on implicit bias at the expense of an attention to both explicit bias and the impact of bias may in fact be harmful to the fight for equality. And Black people — from folks on the street to the first Black Supreme Court Justice — have been trying to tell y’all this." <em>Quoted from abstract</em></p>
<p><a target="_blank" href="https://medium.com/space-anthropology/diversity-is-a-dangerous-set-up-8cee942e7f22">Link to Medium article</a></p>
<p class="tags"><label>Article</label><label>Anthropology</label><label>Racism</label><label>Diversity</label><label>Implicit Bias</label><label>Social Justice</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>A People's History of Computing in the United States</h1>
<h2>Joy Lisi Rankin</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>Destabilizes the Silicon Valley-cenred history of computing, by exploring how students tought computers rather than the other way around, and how students and teachers pioneered the personal and social computing activities we now use. "Rankin offers a radical precedent for a more democratic digital culture, and new models for the next generation of activists, educatiors, coders and makers." <em>Quoted from summary</em></p>
<p><a target="_blank" href="https://www.hup.harvard.edu/catalog.php?isbn=9780674970977">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>History</label><label>Computing</label><label>People's History</label><label>Activism</label><label>Education</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Critical Fabulations: Reworking the methods and margins of design</h1>
<h2>Daniela K. Rosner</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>"Daniela Rosner proposes redefining design as investigative and activist, personal and culturally situated, responsive and responsible. Challenging the field's dominant paradigms and reinterpreting its history, Rosner wants to change the way we historicize the practice, reworking it from the inside. Focusing on the development of computational systems, she takes on powerful narratives of innovation and technology shaped by the professional expertise that has become integral to the field's mounting status within the new industrial economy." Draws on the discourse of feminist technoscience. <em>Summary taken from MIT Press</em></p>
<p><a target="_blank" href="https://direct.mit.edu/books/book/3143/Critical-FabulationsReworking-the-Methods-and">Link to Text, No Free Text Available</a></p>
<p class="tags"><label>book</label><label>design</label><label>history</label><label>technology</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>On the Wrong Side of the Digital Divide in Cleveland, OH</h1>
<h2>Afi Scruggs</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>This article discusses the digital redlining/division between internet service provision within Cleveland, OH, through the profile of David Rosario, an individual who relies solely on his smartphone and its data to apply for jobs, use the internet in any way, because he can't afford the added cost of an internet bill. In a broader way, the article discsuses how predominantly black, inner city neighbourhoods are less likely to have sufficient broadband internet access and this is in part the fault of service comapnies such as AT&amp;T which have deliberately kept the internet infrastructure in these areas obsolete, which in turn disqualifies the residents from affordable broadband internet access programs. In general, the article emphasizes that stable home internet, suitable for video streaming and telehealth for example, are vitally important in this day and age and should be advocated for.</p>
<p><a target="_blank" href="http://beltmag.com/wrong-side-digital-divide/">Link to e-magazine article</a></p>
<p class="tags"><label>Article</label><label>Magazine</label><label>Digital Divide</label><label>Internet</label><label>Accessibility</label><label>Broadband</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Automation Charade</h1>
<h2>Astra Taylor</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>Debunks the myth that AI will soon displace many workers from their jobs and human labour will become obsolete. In fact, human jobs are not going anywhere, these jobs just look different, are taken up by different people, particularly those in the "global south."  For example, our assumption that automatic algorithms filter what we see online occludes the thousands of workers in the global south who parse through traumatizing images to deem them innapropriate. A historical example is how Thomas Jefferson avidly used dumbwaiters, which made it seem like food magically appeared, to occlude how he was exploiting slaves who were still the ones preparing the food. The myth of "fauxtomation" is in fact a capitalist invention to forever make workers feel replaceable and vulnerable </p>
<p><a target="_blank" href="https://logicmag.io/failure/the-automation-charade/">Link to full e-magazine article</a></p>
<p class="tags"><label>Article</label><label>Web Article</label><label>Automation</label><label>AI</label><label>Artificial Intelligence</label><label>Technology Studies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Asking More of Siri and Alexa: Feminine Persona in Service of Surveillance Capitalism</h1>
<h2>Heather Suzanne Woods</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>"This paper illuminates how gendered stereotypes can be leveraged to assuage anxieties surrounding artificially intelligent virtual assistants (AI VA). In particular, the analysis shows that these AI objects routinely traffic in normative gender roles of the feminine as caretaker, mother, and wife in order to obfuscate modes of surveillance, and mediate the relationship users and potential users have with late-capitalist market logics in the platform economy. Mobilizing essentialist feminine personas characterized in this paper as “digital domesticity,” artificially intelligent objects orient users to engage productively with surveillance capitalism as natural." Concentrates on Siri and Alexa. <em>Quoted from abstract</em></p>
<p><a target="_blank" href="https://www.tandfonline.com/doi/abs/10.1080/15295036.2018.1488082">Link to open access article</a></p>
<p class="tags"><label>Article</label><label>Virtural Assistants</label><label>AI</label><label>Artificial Intelligence</label><label>Surveillance Capitalism</label><label>Gender</label><label>Feminist Theory</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Puncturing the Pipeline: Do Technology Companies Alienate Women in Recruiting Sessions?</h1>
<h2>Alison T Wynn and Shelly J. Correll</h2>
<h3>2018</h3>
</header>
<div class="content">
<p>Studies how even after the obstacle of being the few women who make it through computer science education, they face obstacles at the employment level. "Using original observational data from 84 recruiting sessions hosted by technology companies at a prominent university on the US West Coast, we find that company representatives often engage in behaviors that are known to create a chilly environment for women. Through gender-imbalanced presenter roles, geek culture references, overt use of gender stereotypes, and other gendered speech and actions, representatives may puncture the pipeline, lessening the interest of women at the point of recruitment into technology careers." <em>Quoted from abstract</em></p>
<p><a target="_blank" href="https://journals.sagepub.com/doi/abs/10.1177/0306312718756766">Link to open access article</a></p>
<p class="tags"><label>Article</label><label>Gender</label><label>STEM</label><label>Stereotypes</label><label>Work and Occupations</label><label>Gender</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Algorithmic Equity Toolkit</h1>
<h2>ACLU of Washington also made with Micah Epstein</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Working with the ACLU of Washington and the Critical Platform Studies Group, I co-developed and co-designed a print and web toolkit that builds the capacity of community groups to identify, understand, and evaluate government technologies. <em>Description taken from Website</em></p>
<p><a target="_blank" href="https://meandmy.systems/Algorithmic-Equity-Toolkit">Link to Toolkit</a></p>
<p class="tags"><label>toolkit</label><label>worksheet</label><label>algorithmic</label><label>equity</label><label>surveillance</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>AI Now 2019 Report</h1>
<h2>AI Now Institute</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>An annual report describing the concerns and proposals for the AI industry in 2019.  The main points of the executive summary read as follows: 1. The spread of algorithmic management technology in the workplace is increasing the power  asymmetry between workers and employers. AI threatens not only to disproportionately  displace lower-wage earners, but also to reduce wages, job security, and other protections for  those who need it most.  2. Community groups, workers, journalists, and researchers—not corporate AI ethics statements  and policies—have been primarily responsible for pressuring tech companies and  governments to set guardrails on the use of AI. 3. Efforts to regulate AI systems are underway, but they are being outpaced by government  adoption of AI systems to surveil and control. 4. AI systems are continuing to amplify race and gender disparities via techniques like affect  recognition, which has no sound scientific basis.  5. Growing investment in and development of AI has profound implications in areas ranging from  climate change to the rights of healthcare patients to the future of geopolitics and inequities  being reinforced in regions in the global South.  </p>
<p><a target="_blank" href="https://ainowinstitute.org/AI_Now_2019_Report.pdf">Link to full report</a></p>
<p class="tags"><label>Annual Report</label><label>AI</label><label>Artificial Intelligence</label><label>Ethics</label><label>Algorithms</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Disability, Bias, and AI</h1>
<h2>AI Now Institute</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Report that summarizes the themes of a conference by the AI Now Institute and NYU about the intersection of disability, bias and AI and to identify where more research and intervention are needed.  They discussed disability activism and scholarship in relation to AI, and how AI enforced ideas of normal vs. outlier and enforce the marginalization of people with disabilities.  Also, how the use of AI to diagnose people with disabilities (aka the pathologization of disability) can be harmful, how the AI movement can learn from the disability rights movements, and how AI can help disabled people in the future.</p>
<p><a target="_blank" href="https://ainowinstitute.org/disabilitybiasai-2019.pdf">Link to full report</a></p>
<p class="tags"><label>Report</label><label>AI</label><label>Artificial Intelligence</label><label>Disability Activism</label><label>Disability</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Discriminating Systems: Gender, Race and Power in AI</h1>
<h2>AI Now Institute</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Research project which looks into the diversity problem of those working in AI industries and the bias and discrimination in AI systems -- two intertwined problems.  The researchers found that the status quo of the AI industry and its attempts to rememdy the "diversity problem" have been insufficient considering how the origins of AI research have always marginalized women, and poc.  Therefore, there must be a commitment to greater diversity, equality, and transparency around workplace cultures, and AI developpers must consider the biases which AI could perpetuate and specific tests and research should be geared towards preventing this.</p>
<p><a target="_blank" href="https://ainowinstitute.org/discriminatingsystems.pdf">Link to full article</a></p>
<p class="tags"><label>Article</label><label>AI</label><label>Artificial Intelligence</label><label>Diversity</label><label>Industry</label><label>Bias</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Excavating AI: The Politics of Training Sets for Machine Learning</h1>
<h2>AI Now Institute</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Investigates how in the early era of developping machine learning sets, objects and people alike were taught to categorize images into subsets and identify parts of the photo-- for people however, this proved to be more subjective and problematic.  ImageNet, a specific machine learning image recognition site, had problematic labels in their "persons" category ie. designating people as drunk, slattern, loser arbitrarily... The attempt to detect and measure characteristics of people based on their physical appearance is comporably to phrenology of medical anthropologists and eugenicists - that is, usually liberal scientists trying to apply objective methods to study human beings.  Even though sites and databases like ImageNet have taken down their people sections, these data sets have been copied and influenced AI and facial recognition technologies today.</p>
<p><a target="_blank" href="https://excavating.ai">Link to website/article</a></p>
<p class="tags"><label>Article</label><label>Website</label><label>Interactive</label><label>AI</label><label>Artificial Intelligence</label><label>Race</label><label>Racism</label><label>Algorithmic Bias</label><label>Machine Learning</label><label>Data Sets</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Captivating Technology: Race, Carceral Technoscience, and Liberatory Imagination in Everyday Life</h1>
<h2>Ruha Benjamin (ed.)</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>"The contributors to Captivating Technology examine how carceral technologies such as electronic ankle monitors and predictive-policing algorithms are being deployed to classify and coerce specific populations and whether these innovations can be appropriated and reimagined for more liberatory ends." <em>Summary taken from Duke University Press</em></p>
<p><a target="_blank" href="https://www.dukeupress.edu/Assets/PubMaterials/978-1-4780-0381-6_601.pdf">Link to Free Preview</a>
<a target="_blank" href="https://read-dukeupress-edu.proxy3.library.mcgill.ca/books/book/2588/Captivating-TechnologyRace-Carceral-Technoscience">Link to Full Text</a></p>
<p class="tags"><label>book</label><label>technology</label><label>carceral</label><label>surveillance</label><label>algorithms</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Race after technology: abolitionist tools for the new Jim code</h1>
<h2>Ruha Benjamin</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>"Ruha Benjamin cuts through tech-industry hype to understand how emerging technologies can reinforce white supremacy and deepen social inequity. ... Benjamin argues that automation has the potential to hide, speed, and even deepen discrimination, while appearing neutral and even benevolent when compared to racism of a previous era. Presenting the concept of the New Jim Code, she shows how a range of discriminatory designs encode inequity: by explicitly amplifying racial hierarchies, by ignoring but thereby replicating social divisions, or by aiming to fix racial bias but ultimately doing quite the opposite. Moreover, she makes a compelling case for race itself as a kind of tool a technology designed to stratify and sanctify social injustice that is part of the architecture of everyday life."</p>
<p><a target="_blank" href="https://www.wiley.com/en-us/Race+After+Technology:+Abolitionist+Tools+for+the+New+Jim+Code-p-9781509526437">No Free Text Available</a></p>
<p class="tags"><label>book</label><label>race</label><label>technology</label><label>design</label><label>inequity</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Past Decade and Future of AI’s Impact on Society</h1>
<h2>Joanna J. Bryson</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>This article addresses some of the contemporary fears/concerns/myths about AI and outlines how AI has impacted and continues to impact our society. It does not do too much to address how these fears have changed in the past ten years, however.</p>
<p><a target="_blank" href="https://www.bbvaopenmind.com/en/articles/the-past-decade-and-future-of-ais-impact-on-society/">Link to article</a></p>
<p class="tags"><label>AI</label><label>Artificial Intelligence</label><label>Article</label><label>Ethics</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Brotopia: Breaking Up the Boys' Club of Silicon Valley</h1>
<h2>Emily Chang</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>In this book, Bloomberg journalist Emily Chang 'exposes' Silicon Valley's "aggressive, misogynistic, work-at-all costs culture" that actively shuns women from the industry. She explores "how Silicon Valley got so sexist despite its utopian ideals, why bro culture endures despite decades of companies claiming the moral high ground [...] and how women are finally starting to speak out and fight back." <em>Paraphrased from publisher</em></p>
<p><a target="_blank" href="https://www.penguinrandomhouse.com/books/547571/brotopia-by-emily-chang/">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Industry</label><label>Gender</label><label>Computing</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Lecture on Design Justice by Sasha Costanza-Chock</h1>
<h2>Sasha Costanza-Chock</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Presentation which discusses Costanza-Chock's concept of Design Justice. </p>
<p><a target="_blank" href="https://vimeo.com/354276956">Link to Lecture</a></p>
<p class="tags"><label>lecture</label><label>design</label><label>justice</label><label>technology</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The People’s Field Guide to Spotting Surveillance Infrastructure</h1>
<h2>Coveillance Collective and Micah Epstein</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Inspired by birdspotting guides and designed for easy deplyment in the field. I wrote content, co-edited, and designed entire this playful and accessible zine. Technology &amp; Concepts Glossary, How to spot various cameras, An activity about targeted ads, Diagrams, about NSA wiretapping...and so much more!</p>
<p><a target="_blank" href="https://meandmy.systems/Coveillance-Collective">Link to Free Guide</a></p>
<p class="tags"><label>fieldguide</label><label>surveillance</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Invisible Women: Data Bias in a World Designed for Men</h1>
<h2>Caroline Criado-Perez</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Criado-Perez investigates the way that data has failed women, by failing to take gender into account, treating men as the default etc., and how it has resulted in the prioritization of men and neglect of women's safety, responsibilities and travel patterns, misunderstood and mistreated in medicine.</p>
<p><a target="_blank" href="https://www.abramsbooks.com/product/invisible-women_9781419735219/">Link to Text, No Free Text Available</a></p>
<p class="tags"><label>book</label><label>feminism</label><label>women</label><label>data</label><label>discrimination</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>“Color-Blindness” is a Bad Approach to Solving Bias in Algorithms</h1>
<h2>Jessie Daniels</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Challenges the conventional notion that the colourblindness of AI algorithms is the key to racial justice in tehcnology, by showing show racism continues to manifest in these machines, and that taking race into account in fact increases racial literacy.  By hiring more black people, and taking race into account at large when developping these technologies, it will fix the problem better. "Industry leaders, policy makers, and workers who are born in the US or western Europe need racial literacy to become fluent in the difficult discussions of racial inequality. If they’re not, they will inadvertently adopt the worst aspects of the dominant white culture."</p>
<p><a target="_blank" href="https://qz.com/1585645/color-blindness-is-a-bad-approach-to-solving-bias-in-algorithms/">Link to e-magazine article</a></p>
<p class="tags"><label>Magazine article</label><label>Coded Bias</label><label>Algorithmic Bias</label><label>Race</label><label>Machine Learning</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Using Artificial Intelligence to Promote Diversity</h1>
<h2>Paul R. Daugherty, James H. Wilson and Rumman Chowdhury</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>This article looks at AI powered tools which are designed to mitigate biases in hiring, problems which AI had been criticized for recreating at the time of publication.  If care is put into designing AI systems which promote diversity, these systems actually can fare very well.</p>
<p><a target="_blank" href="https://sloanreview.mit.edu/article/using-artificial-intelligence-to-promote-diversity/">Link to article</a></p>
<p class="tags"><label>Article</label><label>Artificial Intelligence</label><label>Diversity</label><label>Design</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Data Feminism</h1>
<h2>Catherine D’Ignazio and Lauren Klein</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Intersectional feminist take on data science and data ethics which accounts for emotion, invisible labour and how the data never "speaks for itself".</p>
<p><a target="_blank" href="https://mitpress.mit.edu/books/data-feminism">Link to Free Text</a></p>
<p class="tags"><label>book</label><label>intersectional</label><label>feminism</label><label>data</label><label>emotional</label><label>labour</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Beyond Hashtags: Racial Politics and Black Digital Networks</h1>
<h2>Sarah Florini</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>In this book, Florini explore how a trans-platform network of black American social media users and content creators, known as "Black Twitter," responded to instances of police brutality and civil unrest, cultivately solidarity and organizing action online. Demonstrates how marginalized individuals use hegemonic technologies to reassert their identitites. <em>Paraphrased from publisher</em></p>
<p><a target="_blank" href="https://nyupress.org/9781479813056/beyond-hashtags/">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Race</label><label>Social Media</label><label>Activism</label><label>Technology Studies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass</h1>
<h2>Mary L. Gray and Siddharth Suri</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>This expose is on the "invisible human workfore that powers the web– and that foreshadows the true future of work. Gray and Suri unveil how services deliverd by companies like Amazon, Google, Microsoft, and Uber can only function smoothly thanks to the judgment and experience of a vast, invisible human labor force. These people doing "ghost work" make the internet seem smart. ...Gray and Suri also show how ghost workers, employers, and society at large can ensure that this new kind of work creates opportunity—rather than misery—for those who do it." <em>Quoted from book site</em></p>
<p><a target="_blank" href="https://ghostwork.info">Link to book website</a></p>
<p class="tags"><label>Book</label><label>Industry</label><label>Class</label><label>Exploitation</label><label>Internet</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Online Othering: Exploring Digital Violence and Discrimination on the Web</h1>
<h2>Emily Harmer and Karen Lumsden (eds)</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Coining the term "online othering" to descibe the toxic behaviours which the internet, social media, etc. breed, this book explores discrimination "encountered and propogated by individuals in online environments." It also "problematizes the dichotomy between real and virtual spaces" and shows how one is simply an extension of the other.</p>
<p><a target="_blank" href="https://www.palgrave.com/gp/book/9783030126322">Link to Text</a></p>
<p class="tags"><label>book</label><label>internet</label><label>social media</label><label>discrimination</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Mainframe, Interrupted: Joan Greenbaum on the Early Days of Tech Worker Organizing</h1>
<h2>Jen Kagan</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Interview with Joan Greenbaum, an individual who has for 50-60 years, dedicated her life to organizing tech workers/unionizing in an attempt to gain influence over the ethics and the values of these large tech companies, such as opposing the war in Vietnam, discrimination in the computer field and against african americans at large, and mass data. In the interview, she talks about the difficulties in unionizing while working in her collective alled Computer People for Peace (CCP), difficulties which included unreceptive computer programmers to the idea of organizing, the way that occupation names have changed over the decades, her zine Interrupt, and the continual importance of this work.</p>
<p><a target="_blank" href="https://logicmag.io/play/joan-greenbaum-on-the-early-days-of-tech-worker-organizing/">Link to e-article</a></p>
<p class="tags"><label>Newspaper/Magazine</label><label>Labor</label><label>Class</label><label>Union</label><label>Zine</label><label>Computing</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Black Software: The Internet &amp; Racial Justice, from the AfroNet to Black Lives Matter</h1>
<h2>Charlton D. McIlwain</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>The story of the racial justice movement online spans nearly five decades and involves engingeers, entrepreneurs, hobbyists, journalists and activists, but this history is virtually unknown. McIlwain chronicles the relationship between African Americans, computing technology and the internet and centres those forgotten figures who made todays online racial justice activism possible. Black Software centres AA's role in the internet's creation and evolution "illuminating both the limits and possibilities for using digital technology to push for racial justice in US and across the globe."</p>
<p><a target="_blank" href="https://mcgill.overdrive.com/media/55DC2B2C-12A6-494C-A813-B7001B623FE9">Link to Text</a></p>
<p class="tags"><label>book</label><label>race</label><label>racialjustice</label><label>internet</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Can the Internet Survive Climate Change?</h1>
<h2>Kevin Lozano</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Article that discusses the tangible, ecological toll of the internet and potential green solutions to the issue of internet, energy, and technolgy which we will face in the coming years.  For example, how high bandwith websites have greater carbon emissions and thus ads which run all over the internet increase the carbon footprint of visiting a website by double. Also, the infrastructure which we rely on for internet, ie. huge warehouses storing data, the pipes and minerals used to transport data, will all become unsustainable in the next few decades. Explores a future internet that is "locally governed, slower, and sustainable."</p>
<p><a target="_blank" href="https://newrepublic.com/article/155993/can-internet-survive-climate-change">Link to full article</a></p>
<p class="tags"><label>article</label><label>Climate Change</label><label>Technology</label><label>Sustainability</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Why AI Can’t Fix Content Moderation</h1>
<h2>Zachary Mack</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>A podcast episode by The Verge. Content moderation is a long-standing challenge for big tech companies. Many of the issues surrounding content moderation have been reported on extensively by The Verge, and they’re now the focus of UCLA professor Sarah T. Roberts’ new book Behind the Screen: Content Moderation in the Shadows of Social Media.</p>
<p><a target="_blank" href="https://www.theverge.com/2019/7/2/20679102/content-moderation-ai-social-media-behind-the-screen-sarah-t-roberts-vergecast">Link to Episode</a></p>
<p class="tags"><label>podcast</label><label>contentmoderation</label><label>bigtech</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>For a Greener Future, We Must Accept There’s Nothing Inherently Sustainable About Going Digital</h1>
<h2>Jessica McLean</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>As the title states, there is nothing inherently green about going digital, in fact, the internet has a huge carbon footprint; data centres use 2% of the world's electricity and generate the same amount of carbon emissions as the global airline industry, training one AI machine would produce 5 times as much as what one car would emit over a persons lifetime, satellites and wires and continuously being build in nature, and big tech doesn't care.<br />
<a target="_blank" href="https://theconversation.com/for-a-greener-future-we-must-accept-theres-nothing-inherently-sustainable-about-going-digital-128125">Link to full article</a></p>
<p class="tags"><label>article</label><label>Climate Change</label><label>Green Technology</label><label>Technology</label><label>Sustainability</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>A.I. Is Not as Advanced as You Might Think</h1>
<h2>Mutale Nakonde</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>A.I. is a field that is no more advanced than the racist society it was build off of. For example, the field is oversaturated by white men with very few black people developping AI with the likes of Google, and the data sets that machine learning takes from are embedded with the racial biases of the humans which created those data sets. </p>
<p><a target="_blank" href="https://zora.medium.com/a-i-is-not-as-advanced-as-you-might-think-97657e9eecdc https://zora.medium.com/a-i-is-not-as-advanced-as-you-might-think-97657e9eecdc">Link to Medium article</a></p>
<p class="tags"><label>AI</label><label>Artificial Intelligence</label><label>Article</label><label>Diversity</label><label>Racism</label><label>Racial Bias</label><label>Industry</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Look Up and Smile: Seeing through Alexa’s Algorithmic Gaze</h1>
<h2>Nassim Parvin</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>This article analyzes Alexa's new feautre "Echo Look," which is touted by Amazon to be a personal stylist, as evidence of how this AI technology is scary and reinforces ideas of the disciplinary gaze, especially on women and their beauty standards.  From the slogan of the camera to capture ones outfit ("look up and smile," extremely catcall-ish) and the way it makes people question their fashion from an automated beauty standard based probably on conventional beauty standards, Echo Look at large is a scary and strange technology.</p>
<p><a target="_blank" href="https://catalystjournal.org/index.php/catalyst/article/view/29592/24756">Link to full article</a></p>
<p class="tags"><label>Article</label><label>Design Justice</label><label>Industry</label><label>Algorithms</label><label>Facial Recognition Technologies</label><label>Gender</label><label>Virtual Assistants</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>A Gendered Perspective on Artificial Intelligence</h1>
<h2>Smriti Parsheera</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Analyzes how the process of knowledge-making in AI can enforce and exacerbate the power structures and biases which have plagued the field of AI from in its inception, from its creators to the gendered-biased society which the AI is learning from.  Proposes strategies for machines to eliminate rather than reinforce human biases such as publically developed standards which embed the concept of "fairness by design," investing in R&amp;D which translates ethical principles into actual practice and reducing gendered distortions in underlying datasets to remove bias in future AI projects.</p>
<p><a target="_blank" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3374955">Link to open access article</a></p>
<p class="tags"><label>Article</label><label>AI</label><label>Artificial Intelligence</label><label>Gender</label><label>Bias</label><label>Fairness by design</label><label>Representation</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Technologies of Control and Our Right of Refusal</h1>
<h2>Seeta Peña Gangadharan</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>"Most of us don’t realise how much digital systems govern access to our basic public services, like education, health and housing. Even more terrifying is how much data is collected about us and used without our knowledge. In 2011, while advocating for broadband adoption policies, Dr Seeta Peña Gangadharan began asking questions about surveillance, privacy, and data profiling. As she reveals a frightening picture of how data profiling works against us, Seeta highlights how people are resisting and why being a good digital citizen means rejecting technological systems that mistreat us." <em>Summary from video description</em></p>
<p><a target="_blank" href="https://www.ted.com/talks/dr_seeta_pena_gangadharan_technologies_of_control_and_our_right_of_refusal">Link to Video</a></p>
<p class="tags"><label>lecture</label><label>video</label><label>TED</label><label>technology</label><label>surveillance</label><label>data</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Decentering Technology in Discourse on Discrimination</h1>
<h2>Seeta Peña Gangadharan and Jedrzej Niklas</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Addresses the problem of algorithmic discrimination from a perspective that decentred the tech aspect and instead employs Nancy Fraser's theory of abnormal justice "which highlights interconnections between maldistribution of economic benefits, misrecognition of marginalized communities, and their misrepresentation in political processes." Uses 30 interviews with civil society representatives in Europe's human rights sector to clarify this idea of decentering.</p>
<p><a target="_blank" href="http://eprints.lse.ac.uk/100227/">Link to Free Text</a></p>
<p class="tags"><label>journal</label><label>article</label><label>technology</label><label>discrimination</label><label>algorithm</label><label>politics</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Dirty Data, Bad Predictions: How Civil Rights Violations Impact Police Data, Predictive Poliving Systems, and Justice</h1>
<h2>Rashida Richardson, Jason M. Schultz and Kate Crawford</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>The researchers looked at how predictive policing systems, which use prior police collected data to forecast criminal activity and allocate resources, are affected by the "dirty policing" and "dirty data" practices of police forces prior: namely, the skewing of data for crime to appear reduced, extortative methods, planting evidence on innovent people etc. which were known policies of many major police departments in America.  By looking at case studies where predictive policing tools were implemented in Chicago, New Orleans and Maricopa Country, the researchers show that there is insufficient account taken of dirty data affecting and perpetuating biased police practices.  Thus, "the use of predictive policing must be treated with high levels of caution and mechanisms for the public to know, access, and reject such systems"</p>
<p><a target="_blank" href="https://www.nyulawreview.org/wp-content/uploads/2019/04/NYULawReview-94-Richardson-Schultz-Crawford.pdf">Link to Free Text</a></p>
<p class="tags"><label>article</label><label>policing</label><label>data</label><label>crime</label><label>carceral</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>A.I. Doesn’t Run the Internet; Exploited Humans Do</h1>
<h2>Sarah T. Roberts and Adam Conover</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Technology expert and UCLA professor of information studies Sarah T. Roberts joins Adam to discuss the oversold fantasy of artificial intelligence, the real humans who labor behind the scenes to moderate your social media feeds, and the psychological effects the work takes on them.</p>
<p><a target="_blank" href="https://www.earwolf.com/episode/a-i-doesnt-run-the-internet-exploited-humans-do-with-sarah-t-roberts/">Link to podcast episode</a></p>
<p class="tags"><label>Podcast</label><label>AI</label><label>Artificial Intelligence</label><label>Ethics</label><label>Labor</label><label>Technology Studies</label><label>Information Studies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Behind the Screen: Content Moderation in the Shadows of Social Media</h1>
<h2>Sarah T. Roberts</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Dives deep into the subject of content moderation on social media, and the idea that what protects us from seeing innapropriate things on social media is computer algorithms - when really, more than 100,000 people are hired to moderate content on social media, sometimes outsourced to other countries like the Phillipines or in Silicon Valley.  An ethnographic account of these workers lives.</p>
<p><a target="_blank" href="https://yalebooks.yale.edu/book/9780300235883/behind-screen">Link to publisher site, no free text available</a></p>
<p class="tags"><label>Book</label><label>Artificial Intelligence</label><label>Social Media</label><label>Content Moderation</label><label>Algorithms</label><label>Labour</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Joys of Standards</h1>
<h2>Andrew Russell and Lee Vinse</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>The authors discuss the societal benefits of standardization, and examples of where the creation of standards have been a cooperative process, involving many parties, that worked to forge more coorporation and convenience after the standard was used. They wish to push back on the idea that standardization is stifling, Kafka-esque, mediocre and comformist, as well as push back on the idea that "innovation," newness and reinventing prior standards is inherently good, to show that standards are joyful for the creators and consumers of technology alike.</p>
<p><a target="_blank" href="https://www.nytimes.com/2019/02/16/opinion/sunday/standardization.html">Link to Text</a></p>
<p class="tags"><label>article</label><label>standardization</label><label>design</label><label>innovation</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Patching Gender: Non-binary Utopias in HCI</h1>
<h2>Katta Spiel, Os Keyes and Pinar Barlas</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>The authors, as non-binary researchers in HCI, present ten "bug reports" of when and how gender binarism present pervasive and diverse challenges in human-computer interaction technologies, while also presenting their utopian "bug fixes," ways that these problems could be easily yet difficultly alleviated. </p>
<p><a target="_blank" href="https://katta.mere.st/wp-content/uploads/2019/04/non_binary_preprint.pdf">Link to full article</a></p>
<p class="tags"><label>Article</label><label>Gender Identity</label><label>Non-binary</label><label>Human-computer interaction technologies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Oh! The Places Your Data Will Go</h1>
<h2>Alexis Takahashi, Sophie Wang, and Chrystal Li (The Free Radicals)</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Part of a series of zines that Free Radicals presented at Tiny Tech Zines on August 11, 2019....An innocent selfie gets uploaded to Instagram and goes on a journey that’s a bit more than she bargained for…</p>
<p>Follow our selfie on a journey through facial recognition algorithms, the corporate and state data sharing environment, and more, oh my! All in spectacular rhyming fashion.</p>
<p>To learn more about real-life examples and critical data frameworks, click the links under select pages to access more resources about different aspects of the data sharing environment. You can also scroll to the bottom and browse the footnotes that share the same links. </p>
<p><em>Description from Website</em></p>
<p><a target="_blank" href="https://freerads.org/2020/09/18/oh-the-places-your-data-will-go/">Link to Free Text</a></p>
<p class="tags"><label>zine</label><label>data</label><label>algorithm</label><label>surveillance</label><label>privacy</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Big Nine: How the Tech Titans and Their Thinking Machines Could Warp Humanity</h1>
<h2>Amy Webb</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>The big nine corporations -- Amazon, Google, Facebook, Tencent, Baidu, Alibaba, Microsoft, IBM and Apple--are the new gods of AI and are short-changing our futures to reap immediate financial gain. In this book, Amy Webb reveals the pervasive, invisible ways in which the foundations of AI -- the people working on the system, their motivations, the technology itself -- is broken. Within our lifetimes, AI will, by design, begin to behave unpredictably, thinking and acting in ways which defy human logic. The big nine corporations may be inadvertently building and enabling vast arrays of intelligent systems that don't share our motivations, desires, or hopes for the future of humanity.</p>
<p><a target="_blank" href="https://www.publicaffairsbooks.com/titles/amy-webb/the-big-nine/9781541773745/">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>AI</label><label>Artificial Intelligence</label><label>Industries</label><label>Computers</label><label>Information Technology</label><label>Corporations</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Age of Surveillance Capitalism: The Fight For a Human Future at the New Frontier of Power</h1>
<h2>Shoshana Zuboff</h2>
<h3>2019</h3>
</header>
<div class="content">
<p>Zuboff tackles the social, political, business, personal, and technological meaning of "surveillance capitalism" as an unprecedented new market form. It is not simply about tracking us and selling ads, it is the business model for an ominous new marketplace that aims at nothing less than predicting and modifying our everyday behavior-- where we go, what we do, what we say, how we feel, who we're with. She shows that the threat has shifted from a totalitarian "big brother" state to a universal global architecture of automatic sensors and smart capabilities, free from democratic oversight and control.</p>
<p class="tags"><label>book</label><label>surveillance</label><label>capitalism</label><label>technology</label><label>algorithm</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Coveillance Toolkits (Guided Workshop)</h1>
<h2>ACLU of Washington, Coveillance Collective, and Micah Epstein</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>Increasingly powerful surveillance tools have shifted the power dynamics between people and institutions. To address this new dynamic, we’ve been creating a toolkit, in collaboration with the ACLU of Washington, that demystifies surveillance technologies in Seattle in the historical context of structural inequities in the United States. Below are a set of guides for facilitating workshops focusing on different aspects of surveillance: historical, visual, physical, and somatic.
<em>Description taken to Website</em></p>
<p><a target="_blank" href="https://coveillance.org/">Link to Free Materials</a></p>
<p class="tags"><label>workshop</label><label>toolkits</label><label>surveillance</label><label>historical</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Facial Recognition Technologies: A Primer</h1>
<h2>AI Now Institute</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>An introduction written for a general audience on what facial recognition technology is, its applications, common technology and terminology, as well as its difficulties.</p>
<p><a target="_blank" href="https://global-uploads.webflow.com/5e027ca188c99e3515b404b7/5ed1002058516c11edc66a14_FRTsPrimerMay2020.pdf">Link to free zine</a></p>
<p class="tags"><label>Zine</label><label>Facial Recognition Technologies</label><label>Machine Learning</label><label>FRTs</label><label>Algorithms</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Distributed Blackness: African American Cybercultures</h1>
<h2>Andre Brock Jr.</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>Centres blackness in discussing contemporary digital culture, how different platforms have uniquely changed African American identity online, and vice versa.  "Drawing on critical race theory, linguistics, rhetoric, information studies, and science and technology studies, Brock tabs between black-dominated technologies, websites, and social media to build a set of black beliefs about technology." <em>Quote taken from book summary</em></p>
<p><a target="_blank" href="https://nyupress.org/9781479829965/distributed-blackness/">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Critical Race Theory</label><label>Race</label><label>Digital Culture</label><label>Linguistic</label><label>Information Studies</label><label>Technology Studies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Design Justice: Community-Led Practices to Build the Worlds We Need</h1>
<h2>Sasha Constanza-Chock</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>This book explores the theory and practice of design justice, demonstrates how universalist design principles and practices erase certain groups of people—specifically, those who are intersectionally disadvantaged or multiply burdened under the matrix of domination (white supremacist heteropatriarchy, ableism, capitalism, and settler colonialism)—and invites readers to “build a better world, a world where many worlds fit; linked worlds of collective liberation and ecological sustainability.” Along the way, the book documents a multitude of real-world community-led design practices, each grounded in a particular social movement. Design Justice goes beyond recent calls for design for good, user-centered design, and employment diversity in the technology and design professions; it connects design to larger struggles for collective liberation and ecological survival. <em>Summary taken from MIT Press</em></p>
<p><a target="_blank" href="https://direct.mit.edu/books/book/4605/Design-JusticeCommunity-Led-Practices-to-Build-the">Link to Free Text</a></p>
<p class="tags"><label>book</label><label>design</label><label>justice</label><label>oppression</label><label>liberation</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Data Feminism Reading Group</h1>
<h2>D’Ignazio, Catherine, Lauren Klein and audience</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>Global reading group where authors of Data Feminism (see above) presented highlights from each chapter of Data Feminism followed by audience Q&amp;A.</p>
<p><a target="_blank" href="http://datafeminism.io/blog/book/data-feminism-reading-group/">Link to Videos</a></p>
<p class="tags"><label>video</label><label>reading</label><label>group</label><label>data</label><label>feminism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Hacking Diversity: The Politics of Inclusion in Open Technology Cultures</h1>
<h2>Christina Dunbar-Hester</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>Hacking, as a mode of technical and cultural production, is commonly celebrated for its extraordinary freedoms of creation and circulation. Yet surprisingly few women participate in it: rates of involvement by technologically skilled women are drastically lower in hacking communities than in industry and academia. Hacking Diversity investigates the activists engaged in free and open-source software to understand why, despite their efforts, they fail to achieve the diversity that their ideals support. <em>Description taken from Summary</em></p>
<p><a target="_blank" href="https://press.princeton.edu/books/paperback/9780691192888/hacking-diversity">Link to Free Preview</a></p>
<p class="tags"><label>hacking</label><label>diversity</label><label>book</label><label>technology</label><label>women</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Radical AI Podcast</h1>
<h2>Dylan Doyle-Burke and Jessie Smith</h2>
<h3>2020 - present</h3>
</header>
<div class="content">
<p>A podcast centring radical ideas in a world transformed by technology, using dialogue and storytelling while probing the advancement of the field of AI ethics. Their vision is for a future of AI Ethics "becoming fundamentally representative of a diversity of stories, voices, and ideas that are accessible, bold, and transformative for all individuals and communities that use, design, and engage with AI technology." <em>Quote from website</em></p>
<p><a target="_blank" href="https://www.radicalai.org">Link to podcast site</a></p>
<p class="tags"><label>Podcast</label><label>Artificial Intelligence</label><label>AI</label><label>Ethics</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Computer's Voice: From Star Trek to Siri</h1>
<h2>Liz W. Faber</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>In this book, Faber analyzes real and fictional cases of voice-interactive computers such as Star Trek, 2001 Space Odyssey, Her, Siri, and more. She analyzes why some computer-based personal assistants are gendered female, others male, and how these gender constructions reify the gender binary and represent cultural attitudes towards embodiment and computer anthropomorphism. The Computer's Voice "breaks new ground in questions surrounding media, technology, and gender. It makes important contributions to conversations around the gender gap and the increasing acceptance of transgender people."</p>
<p><a target="_blank" href="https://www.upress.umn.edu/book-division/books/the-computeras-voice">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Gender</label><label>Trans</label><label>AI</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>#HashtagActivism Networks of Race and Gender Justice</h1>
<h2>Sarah J. Jackson, Moya Bailey and Brooke Foucault Wells</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>"How marginalized groups use Twitter to advance counter-narratives, preempt political spin, and build diverse networks of dissent."  Specifically discusses how Twitter and the use of hashtags, has served to change the nature of political organization for marginalized groups, hashtags such as #MeToo, #BlackLivesMatter, #GirlsLikeUs, etc.</p>
<p><a target="_blank" href="https://direct.mit.edu/books/book/4597/HashtagActivismNetworks-of-Race-and-Gender-Justice">Link to open access book</a></p>
<p class="tags"><label>Social Media</label><label>Twitter</label><label>Social Activism</label><label>Politics</label><label>Book</label><label>Open Access</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Coded Bias</h1>
<h2>Shalini Kantayya (dir.)</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>Documentary which tracks MIT Media Lab scholar Joy Buolawini's trajectory in the field of AI, finding out the coded bias against women and poc in facial recognition technology, and many deeper coded biases in AI.  She then joins forces with other concerned experts to form a justice league -- informing the public and advocating for public scrutiny and more legislation.</p>
<p><a target="_blank" href="https://www.sundance.org/projects/code-for-bias">Link to film page</a></p>
<p class="tags"><label>Film</label><label>Documentary</label><label>AI</label><label>Artificial Intelligence</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Queer Times, Black Futures</h1>
<h2>Kara Keeling</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>"Queer Times, Black Futures considers the promises and pitfalls of imagination, technology, futurity, and liberation as they have persisted in and through racial capitalism. Kara Keeling explores how the speculative fictions of cinema, music, and literature that center black existence provide scenarios wherein we might imagine alternative worlds, queer and otherwise. In doing so, Keeling offers a sustained meditation on contemporary investments in futurity, speculation, and technology, paying particular attention to their significance to queer and black freedom." <em>Summary from NYU Press</em></p>
<p><a target="_blank" href="https://www.perlego.com/book/921319/queer-times-black-futures-pdf">Link to Free Text with Free Trial to Perlego</a></p>
<p class="tags"><label>book</label><label>specualtivefiction</label><label>afrofuturism</label><label>queer</label><label>futurity</label><label>technology</label><label>media</label><label>music</label><label>film</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Information Activism: A Queer History of Lesbian Media Technologies</h1>
<h2>Cait McKinney</h2>
<h3>2020</h3>
</header>
<div class="content">
<p><em>Information Activism</em> traces how feminists from the 1970s to the present developed communication networks, databases, and digital archives as the foundation for their activism. These people had to learn collectively how to archive their work and transition from paper to digital-based archival practices, for example. "McKinney demontrates how groups with precarious access to control over information create their own innovative techniques for generating and sharing knowledge."</p>
<p><a target="_blank" href="https://www.dukeupress.edu/information-activism">Link to publisher's site, no free text available</a></p>
<p class="tags"><label>Book</label><label>Information Studies</label><label>Media Studies</label><label>Media Technologies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>girl.is.a.four.letter.word The Collective Practices of Amateur Self-Imag(in)ing and Personal Website Production 1996 to 2001</h1>
<h2>Magdalena Olszanowski</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>Philosophical history of the early internet (1996-2001) from the perspective of women who were using nascent internet technology to share feminist ideas, art, etc. Challenges the typical early history of the internet (a field which is growing as we speak), a history which in and of itself is hard to trace because much of the early internet is erased or forgotten.  Dominant narratives focus on white male entrepreneurs capitalizing off of the internet rather than women who used "proto-social media" to self-imag(in)e which ultimately "reshape a feminist intimate public into a new genre of friendship predicated on the aesthetics and forms of circulation of the work." Draws from feminist cyberculture, feminist phenomenology and affect theory.</p>
<p><a target="_blank" href="https://spectrum.library.concordia.ca/986669/1/Olszanowski_PhD_S2020.pdf">Link to Text</a></p>
<p class="tags"><label>dissertation</label><label>feminism</label><label>internet</label><label>cyberculture</label><label>cyberfeminism</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>When Proof Is Not Enough</h1>
<h2>Mimi Onuoha</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>Article written re: 2020 police protests questionning whether data itself, or in this case video documentation is enough to spark societal empathy and change.  Onuoha uses their background in teaching data-collection to demonstrate that even when historically and experimentally, people are confronted with documentation which contradicts the belief systems of individuals, automatic acceptance of the truth is seldom the result.  Therefore, video of police brutality alone, has its limits in pushing for racial justice.</p>
<p><a target="_blank" href="https://fivethirtyeight.com/features/when-proof-is-not-enough/">Link to Text</a></p>
<p class="tags"><label>article</label><label>police</label><label>violence</label><label>empathy</label><label>racial</label><label>justice</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Glitch Feminism: A Manifesto</h1>
<h2>Legacy Russel</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>"The divide between the digital and the real world no longer exists: we are connected all the time. How do we find out who we are within this digital era? Where do we create the space to explore our identity? How can we come together and create solidarity?
The glitch is often dismissed as an error, a faulty overlaying, but, as Legacy Russell shows, liberation can be found within the fissures between gender, technology and the body that it creates. The glitch offers the opportunity for us to perform and transform ourselves in an infinite variety of identities. In Glitch Feminism, Russell makes a series of radical demands through memoir, art and critical theory, and the work of contemporary artists who have travelled through the glitch in their work." <em>Quoted from summary</em></p>
<p><a target="_blank" href="https://www.penguinrandomhouse.com/books/646946/glitch-feminism-by-legacy-russell/">Link to publisher site</a></p>
<p class="tags"><label>Cyberfeminism</label><label>Book</label><label>Gender</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Artificial Intelligence Themes Explored in Canberra Duo B(if)tek's Album Titled 2020 Have 'Come to Pass'</h1>
<h2>Ainsleigh Sheridan</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>Journalist interviews and discusses the femme electronic music duo B(if)tek who released an album in 2000 named "2020," which hinted at a future which involved artificial intelligence, and what that would look like.  While one member of the group, Nicole Skeltys, shifted to folk music after the band dissolved, the other, Kate Crawford, went on to found the AI Now Institute @ NYU.</p>
<p><a target="_blank" href="https://www.abc.net.au/news/2020-08-12/two-decades-on-ai-explored-in-canberra-duo-b(if)tek-album-2020/12544272">Link to news article</a></p>
<p class="tags"><label>Article</label><label>Interview</label><label>Artificial Intelligence</label><label>AI</label><label>Gender</label><label>B(if)tek</label><label>Music</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>"What are your favourite art chat bots?"</h1>
<h2>Caroline Sinders</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>People sharing their favourite art chat bots, machine learned bots and AI on twitter. About six responses</p>
<p><a target="_blank" href="https://twitter.com/carolinesinders/status/1259835481031872513">Link to Twitter thread</a></p>
<p class="tags"><label>Twitter thread</label><label>tweet</label><label>art chat bots</label><label>AI</label><label>Artificial Intelligence</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>UCLA Center for Critical Internet Inquiry receives $2.9M Award to launch Minderoo Initiative on Technology and Power</h1>
<h2>UCLA Newsroom</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>In August 2020, the UCLA Center of Critical Inquiry was awarded 2.9 million dollars by the Mineroo Foundation "to participate in an international network of scholars committed to challenging the unjust impact of digital technologies on society through research, education, and the arts."  "The new funding will nurture a hub of research at UCLA exploring the intersection of technology, power, and society and activating paradigm and culture-shifting work. The Initiative will be led by the Center’s co-directors and co-founders, Safiya Umoja Noble and Sarah T. Roberts. " <em>Quoted from text</em></p>
<p><a target="_blank" href="https://ampersand.gseis.ucla.edu/ucla-center-for-critical-internet-inquiry-receives-2-9m-award-to-launch-minderoo-initiative-on-technology-and-power/">Link to press release</a></p>
<p class="tags"><label>Press release</label><label>UCLA</label><label>Technology</label><label>University</label><label>Research</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Atlas of Anonmalous AI</h1>
<h2>Ben Vickens and K. Allado-McDowe II</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>"The Atlas of Anomalous AI is a compelling and surprising map of our complex relationship to intelligence, from ancient to emerging systems of knowledge. [This text] presents a hyperdimensional view of the world, through a broad range of perspectives that explore the question of what AI has been and what it is becoming. Key texts on modelling, prediction and automation are brought together with stories of science fiction, dreams and human knowledge, set among visionary and surreal images."</p>
<p><a target="_blank" href="https://ignota.org/products/atlas-of-anomalous-ai">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>AI</label><label>Artificial Intelligence</label><label>Science Fiction</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>The Innovation Delusion: How Our Obsession with the New Has Disrupted the Work that Matters Most</h1>
<h2>Lee Vinsel and Andrew L. Russell</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>Historians of technology Lee Vinsel and Andrew L. Russell argue in The Innovation Delusion that American technological fixation on what is new, disruptive and innovated devalues most of the work that underpins modern life -- that being maintenance, care and upkeep of pre-existing technology. The book functions as a manifesto against this trend of 'innovation.'</p>
<p><a target="_blank" href="https://www.penguinrandomhouse.com/books/576816/the-innovation-delusion-by-lee-vinsel-and-andrew-l-russell/">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Technology</label><label>Innovation</label><label>Maintenance</label><label>Technology Studies</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Disability Visibility: First Person Stories from the Twenty-First Century</h1>
<h2>Alice Wong</h2>
<h3>2020</h3>
</header>
<div class="content">
<p>An anthology of personal essays, first person accounts from contemporary disabled writers such as Keah Brown and Haben Girma. "This anthology gives a glimpse of the vast richness and complexity of the disabled experience, highlighting the passions, talents, and everyday lives of this community. It invites readers to question their own assumptions and understandings. It celebrates and documents disability culture in the now. It looks to the future and past with hope and love." <em>Quoted from project website</em></p>
<p><a target="_blank" href="https://disabilityvisibilityproject.com/book/">Link to book website</a></p>
<p class="tags"><label>Book</label><label>Disability</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Atlas of AI</h1>
<h2>Kate Crawford</h2>
<h3>2021</h3>
</header>
<div class="content">
<p>"Crawford reveals how the global networks underpinning AI technology are damaging the environment, entrenching inequality, and fueling a shift toward undemocratic governance. She takes us on a journey through the mining sites, factories, and vast data collections needed to make AI ""work"" — powerfully revealing where they are failing us and what should be done.</p>
<p>While technical systems present a veneer of objectivity and neutrality, Crawford shows how they are designed to serve and intensify existing systems of power. Drawing on a decade of original research, she shows how the new infrastructures of AI reflect the beliefs and perspectives of a small group of people and serve the interests of the few at the expense of the many." <em>Summary taken from author's website</em></p>
<p><a target="_blank" href="https://www.katecrawford.net/">Link to author's website</a></p>
<p class="tags"><label>Book</label><label>AI</label><label>Artificial Intelligence</label><label>Industry</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Flash Forward: An Illustrated Guide to Possible and Not So Possible Tomorrows</h1>
<h2>Rose Eveleth</h2>
<h3>2021</h3>
</header>
<div class="content">
<p>This book "takes readers on a journey from speculative fiction to speculative “fact.” Producer and host of the podcast Flash Forward, Rose Eveleth poses provocative questions about our future, which are brought to life by 12 of the most imaginative comics and graphic artists at work, including Matt Lubchanksy, Sophie Goldstein, Ben Passmore, and Box Brown. Each artist chooses a subject close to their heart—Ignatz Award nominee Julia Gfrörer, for instance, will imagine a future in which robots make art—and presents their chosen future in their own style. Drawing on her interviews with experts in various fields of study, Eveleth will then report on what is complete fantasy and what is only just out of reach in insightful essays following the comics. This book introduces compelling visions of the future and vividly explores the human consequences of developing technologies. Flash Forward reveals how complicated, messy, incredible, frightening, and strange our future might be." <em>Quoted from website</em></p>
<p><a target="_blank" href="https://www.flashforwardpod.com/book/">Link to book website</a></p>
<p class="tags"><label>Book</label><label>Illustrated</label><label>Futurity</label><label>Speculative Fiction</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Your Computer is On Fire</h1>
<h2>Thomas S. Mullaney, Benjamin Peters, Mar Hicks and Kavita Philip</h2>
<h3>2021</h3>
</header>
<div class="content">
<p>With contributions from Safiya Noble, Nathan Ensmenger, Mar Hicks and more, "The essays in Your Computer Is on Fire interrogate how our human and computational infrastructures overlap, showing why technologies that centralize power tend to weaken democracy. These practices are often kept out of sight until it is too late to question the costs of how they shape society. From energy-hungry server farms to racist and sexist algorithms, the digital is always IRL, with everything that happens algorithmically or online influencing our offline lives as well. Each essay proposes paths for action to understand and solve technological problems that are often ignored or misunderstood." <em>Quoted from publisher summary</em></p>
<p><a target="_blank" href="https://mitpress.mit.edu/books/your-computer-fire">Link to publisher site</a></p>
<p class="tags"><label>Book</label><label>Technology Studies</label><label>Computing</label><label>AI</label></p>
</div>
</article>
<article>
<header class="heading">
<h1>Data Bites</h1>
<h2>Data and Society</h2>
<h3>2021</h3>
</header>
<div class="content">
<p>“Databites” is a regular speaker series that presents timely conversations about the purpose and power of technology today. Speakers bridge our interdisciplinary research with broader public conversations about the societal implications of data and automation.</p>
<p><a target="_blank" href="https://datasociety.net/library/databites/">Link to podcast site</a></p>
<p class="tags"><label>Podcast</label><label>Technology</label><label>Data</label><label>Automation</label></p>
</div></article>
<script src="js/scripts.js"></script>
</body>
</html>